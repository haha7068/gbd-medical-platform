import streamlit as st
import pandas as pd
import numpy as np
import matplotlib
from matplotlib import pyplot as plt
from scipy import stats
import tempfile
import os
import chardet
import json
import plotly.express as px

# é¡µé¢é…ç½®
st.set_page_config(page_title="GBDåŒ»å­¦æ•°æ®åˆ†æä¸å¯è§†åŒ–å¹³å°", layout="wide")
st.title("ğŸŒ GBDåŒ»å­¦æ•°æ®åˆ†æä¸å¯è§†åŒ–å¹³å°\nGBD Medical Data Analysis & Visualization Platform")


# ========= ğŸ“‚ æ•°æ®ä¸Šä¼ åŒº Upload Section =========
st.sidebar.header("ğŸ“‚ æ•°æ®å¯¼å…¥ Upload Data")
uploaded_files = st.sidebar.file_uploader(
    "ä¸Šä¼ ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®æ–‡ä»¶ï¼ˆæ”¯æŒ CSV, Excel, JSONï¼‰",
    type=["csv", "xlsx", "xls", "json"],
    accept_multiple_files=True
)
# ========== ğŸ§¹ æ¸…é™¤ä¸Šä¼ æ–‡ä»¶ç¼“å­˜ Clear Cache Section ========== #
CACHE_FILE = "uploaded_data_cache.json"#å®šä¹‰ç¼“å­˜è·¯å¾„
if st.sidebar.button("ğŸ§¹ æ¸…é™¤ä¸Šä¼ ç¼“å­˜ Clear Uploaded Cache"):
    if os.path.exists(CACHE_FILE):
        os.remove(CACHE_FILE)
        st.success("âœ… ä¸Šä¼ æ–‡ä»¶ç¼“å­˜å·²æ¸…é™¤ï¼Cache Cleared Successfully!")
    else:
        st.info("âš ï¸ å½“å‰æ²¡æœ‰ç¼“å­˜æ–‡ä»¶ï¼Œæ— éœ€æ¸…é™¤ã€‚")



def save_cache(file_info):
    with open(CACHE_FILE, "w", encoding="utf-8") as f:
        json.dump(file_info, f)

def load_cache():
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

def check_data_quality(df, filename=""):
    problems = []
    if df.empty:
        problems.append("âŒ æ–‡ä»¶ä¸ºç©º Empty file")
    if df.shape[1] < 2:
        problems.append("âš ï¸ åˆ—æ•°è¿‡å°‘ Less than 2 columns")
    if df.isnull().mean().mean() > 0.3:
        problems.append("âš ï¸ ç¼ºå¤±å€¼æ¯”ä¾‹è¶…è¿‡30% High missing values (>30%)")
    if (df.dtypes == 'object').mean() > 0.8:
        problems.append("âš ï¸ 80%ä»¥ä¸Šåˆ—æ˜¯æ–‡æœ¬å‹ High proportion of text columns (>80%)")
    if df.select_dtypes(include=[np.number]).shape[1] == 0:
        problems.append("âš ï¸ æ²¡æœ‰ä»»ä½•æ•°å€¼å‹å­—æ®µ No numeric columns")

    if problems:
        st.warning(f"âš ï¸ æ–‡ä»¶ {filename} å­˜åœ¨æ½œåœ¨é—®é¢˜ Potential issues:")
        for p in problems:
            st.write(p)
    else:
        st.success(f"âœ… æ–‡ä»¶ {filename} æ£€æŸ¥é€šè¿‡ï¼Format Check Passedï¼")


file_info_cache = {}

if uploaded_files:
    file_info_cache = {}
    dfs = []
    for uploaded_file in uploaded_files:
        filename = uploaded_file.name
        suffix = filename.split(".")[-1].lower()
        temp_path = os.path.join(tempfile.gettempdir(), filename)
        with open(temp_path, "wb") as f:
            f.write(uploaded_file.read())
        try:
            if suffix == "csv":
                with open(temp_path, "rb") as f:
                    encoding = chardet.detect(f.read())["encoding"]
                df = pd.read_csv(temp_path, encoding=encoding)
            elif suffix in ["xlsx", "xls"]:
                df = pd.read_excel(temp_path)
            elif suffix == "json":
                df = pd.read_json(temp_path)
            else:
                continue
            dfs.append(df)
            file_info_cache[filename] = temp_path
            check_data_quality(df, filename)

        except Exception as e:
            st.error(f"{filename} æ–‡ä»¶è¯»å–å¤±è´¥ï¼š{e}")
    save_cache(file_info_cache)
else:
    cached_files = load_cache()
    dfs = []
    for filename, temp_path in cached_files.items():
        try:
            suffix = filename.split(".")[-1].lower()
            if suffix == "csv":
                with open(temp_path, "rb") as f:
                    encoding = chardet.detect(f.read())["encoding"]
                df = pd.read_csv(temp_path, encoding=encoding)
            elif suffix in ["xlsx", "xls"]:
                df = pd.read_excel(temp_path)
            elif suffix == "json":
                df = pd.read_json(temp_path)
            else:
                continue
            dfs.append(df)
            st.sidebar.success(f"ä»ç¼“å­˜åŠ è½½ï¼š{filename}")
        except:
            st.sidebar.warning(f"âš  æ— æ³•ä»ç¼“å­˜åŠ è½½ {filename}")

if not dfs:
    st.info("è¯·ä¸Šä¼ æ•°æ®åå¼€å§‹åˆ†æ~")
# ========= ğŸ“„ æ•°æ®æµè§ˆä¸é¢„å¤„ç†åŒº Data Preview & Preprocessing =========
if dfs:
    st.success(f"âœ… æˆåŠŸåŠ è½½ {len(dfs)} ä¸ªæ•°æ®é›†")

    for i, df in enumerate(dfs):
        st.header(f"ğŸ“„ æ•°æ®é›† {i+1} é¢„è§ˆ Dataset {i+1}")
        st.dataframe(df.head())

        # ========== ğŸ” ç­›é€‰ä¸åˆ†ç»„ Filter & Group ==========
        st.subheader("ğŸ” æ•°æ®ç­›é€‰ä¸åˆ†ç»„ Group & Filter")

        filter_cols = df.columns.tolist()
        selected_filter_col = st.selectbox(
            f"é€‰æ‹©ç­›é€‰å­—æ®µ Dataset{i+1}",
            filter_cols,
            key=f"filtercol_{i}"
        )

        if np.issubdtype(df[selected_filter_col].dtype, np.number):
            min_val = float(df[selected_filter_col].min())
            max_val = float(df[selected_filter_col].max())
            selected_range = st.slider(
                f"é€‰æ‹©æ•°å€¼èŒƒå›´ {selected_filter_col}",
                min_value=min_val, max_value=max_val,
                value=(min_val, max_val),
                key=f"range_{i}"
            )
            if st.button(f"åº”ç”¨æ•°å€¼ç­›é€‰ Apply Numeric Filter Dataset{i+1}", key=f"numfiltbtn_{i}"):
                df = df[(df[selected_filter_col] >= selected_range[0]) & (df[selected_filter_col] <= selected_range[1])]
                st.success(f"ç­›é€‰åå‰©ä½™ {len(df)} è¡Œ")
                st.dataframe(df)
        else:
            unique_vals = df[selected_filter_col].dropna().unique().tolist()
            selected_vals = st.multiselect(
                f"é€‰æ‹©åˆ†ç±»å€¼ {selected_filter_col}",
                unique_vals, default=unique_vals[:1],
                key=f"catfilt_{i}"
            )
            if st.button(f"åº”ç”¨åˆ†ç±»ç­›é€‰ Apply Categorical Filter Dataset{i+1}", key=f"catfiltbtn_{i}"):
                df = df[df[selected_filter_col].isin(selected_vals)]
                st.success(f"ç­›é€‰åå‰©ä½™ {len(df)} è¡Œ")
                st.dataframe(df)

        # ========== ğŸ§¹ ç¼ºå¤±å€¼å¤„ç† Missing Value Handling ==========
        st.subheader("ğŸ§¹ ç¼ºå¤±å€¼å¤„ç† Missing Values")

        missing_method = st.selectbox(
            "é€‰æ‹©å¤„ç†æ–¹å¼",
            ["ä¸å¤„ç†", "åˆ é™¤ç¼ºå¤±è¡Œ", "ç”¨å‡å€¼å¡«å……", "ç”¨ä¸­ä½æ•°å¡«å……", "ç”¨ä¼—æ•°å¡«å……", "çº¿æ€§æ’å€¼"],
            key=f"missing_{i}"
        )
        if st.button(f"åº”ç”¨ç¼ºå¤±å€¼å¤„ç† Apply Missing Handling Dataset{i+1}", key=f"missingbtn_{i}"):
            if missing_method == "åˆ é™¤ç¼ºå¤±è¡Œ":
                df = df.dropna()
            elif missing_method == "ç”¨å‡å€¼å¡«å……":
                df = df.fillna(df.mean(numeric_only=True))
            elif missing_method == "ç”¨ä¸­ä½æ•°å¡«å……":
                df = df.fillna(df.median(numeric_only=True))
            elif missing_method == "ç”¨ä¼—æ•°å¡«å……":
                df = df.fillna(df.mode().iloc[0])
            elif missing_method == "çº¿æ€§æ’å€¼":
                df = df.interpolate()
            st.success("âœ… ç¼ºå¤±å€¼å¤„ç†å®Œæˆï¼")
            st.dataframe(df)

        # ========== ğŸ“ æ ‡å‡†åŒ–ä¸å½’ä¸€åŒ– Normalization ==========
        st.subheader("ğŸ“ æ•°æ®æ ‡å‡†åŒ–ä¸å½’ä¸€åŒ– Normalization")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        scale_cols = st.multiselect(
            f"é€‰æ‹©éœ€è¦æ ‡å‡†åŒ–/å½’ä¸€åŒ–çš„å­—æ®µ Dataset{i+1}",
            numeric_cols,
            key=f"scalecols_{i}"
        )
        scale_method = st.selectbox(
            "é€‰æ‹©å˜æ¢æ–¹å¼",
            ["Z-Scoreæ ‡å‡†åŒ–", "æœ€å°-æœ€å¤§å½’ä¸€åŒ–"],
            key=f"scalemethod_{i}"
        )

        if st.button(f"åº”ç”¨æ ‡å‡†åŒ–å½’ä¸€åŒ– Apply Scaling Dataset{i+1}", key=f"scalebtn_{i}"):
            if scale_cols:
                for col in scale_cols:
                    if scale_method == "Z-Scoreæ ‡å‡†åŒ–":
                        mean = df[col].mean()
                        std = df[col].std()
                        df[f"{col}_Zscore"] = (df[col] - mean) / std
                    elif scale_method == "æœ€å°-æœ€å¤§å½’ä¸€åŒ–":
                        min_val = df[col].min()
                        max_val = df[col].max()
                        if max_val != min_val:
                            df[f"{col}_MinMax"] = (df[col] - min_val) / (max_val - min_val)
                st.success("âœ… æ•°æ®å˜æ¢å®Œæˆï¼")
                st.dataframe(df)
            else:
                st.warning("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå­—æ®µè¿›è¡Œæ ‡å‡†åŒ–/å½’ä¸€åŒ–ï¼")
# ========= ğŸ“Š æè¿°æ€§ç»Ÿè®¡ä¸åŸºç¡€åˆ†æåŒº Descriptive Stats & Basic Analysis =========
        # ========== ğŸ“Š æè¿°æ€§ç»Ÿè®¡ Descriptive Statistics ==========
        st.subheader("ğŸ“Š æè¿°æ€§ç»Ÿè®¡ Descriptive Statistics")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        desc_numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        if desc_numeric_cols:
            selected_desc_cols = st.multiselect(
                "é€‰æ‹©è¦è¿›è¡Œç»Ÿè®¡æè¿°çš„å­—æ®µ",
                desc_numeric_cols,
                default=desc_numeric_cols[:2],
                key=f"desc_cols_{i}"
            )

            if st.button(f"æ‰§è¡Œæè¿°æ€§ç»Ÿè®¡ Run Description Dataset{i + 1}", key=f"descbtn_{i}"):
                if selected_desc_cols:
                    desc_stats = df[selected_desc_cols].describe().T
                    desc_stats["æ–¹å·® Variance"] = df[selected_desc_cols].var()
                    desc_stats["ä¼—æ•° Mode"] = [
                        df[col].mode().iloc[0] if not df[col].mode().empty else np.nan
                        for col in selected_desc_cols
                    ]
                    st.success("âœ… æè¿°æ€§ç»Ÿè®¡å®Œæˆ Description Completed")
                    st.dataframe(desc_stats)

                    # ==== ğŸš€ å¢å¼ºç‰ˆå¯è§†åŒ–éƒ¨åˆ† ====
                    st.markdown("### ğŸ“Š å„å­—æ®µåˆ†å¸ƒç›´æ–¹å›¾ Histograms of Selected Fields")

                    import plotly.express as px

                    for col in selected_desc_cols:
                        fig = px.histogram(
                            df,
                            x=col,
                            nbins=30,
                            title=f"ğŸ“Š {col} åˆ†å¸ƒç›´æ–¹å›¾ Histogram of {col}",
                            marginal="box"
                        )
                        fig.write_image(f"desc_histogram_{col}.png", scale=2)
                        st.plotly_chart(fig, use_container_width=True)

                else:
                    st.warning("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå­—æ®µè¿›è¡Œæè¿°ç»Ÿè®¡")

        # ========== ğŸ”— ç›¸å…³æ€§åˆ†æ Correlation Analysis ========== #
        st.subheader("ğŸ”— ç›¸å…³æ€§åˆ†æ Correlation Analysis")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        correlation_cols = df.select_dtypes(include=np.number).columns.tolist()

        if correlation_cols:
            selected_corr_cols = st.multiselect(
                "é€‰æ‹©è¿›è¡Œç›¸å…³æ€§åˆ†æçš„æ•°å€¼åˆ— Select Numeric Columns for Correlation",
                correlation_cols,
                key=f"correlation_cols_{i}"
            )

            correlation_method = st.radio(
                "é€‰æ‹©ç›¸å…³æ€§è®¡ç®—æ–¹æ³• Select Correlation Method",
                ["Pearsonç›¸å…³ç³»æ•° Pearson", "Spearmanç§©ç›¸å…³ç³»æ•° Spearman"],
                key=f"correlation_method_{i}"
            )

            if st.button(f"æ‰§è¡Œç›¸å…³æ€§åˆ†æ Run Correlation Analysis Dataset{i + 1}", key=f"correlation_run_{i}"):
                try:
                    if selected_corr_cols:
                        df_corr = df[selected_corr_cols].dropna()

                        if correlation_method == "Pearsonç›¸å…³ç³»æ•° Pearson":
                            corr_matrix = df_corr.corr(method='pearson')
                        else:
                            corr_matrix = df_corr.corr(method='spearman')

                        st.success("âœ… ç›¸å…³æ€§åˆ†æå®Œæˆ Correlation Analysis Completed")
                        st.dataframe(corr_matrix)

                        # çƒ­åŠ›å›¾ç»˜åˆ¶
                        import plotly.figure_factory as ff

                        z = corr_matrix.values
                        x = list(corr_matrix.columns)
                        y = list(corr_matrix.index)

                        fig = ff.create_annotated_heatmap(
                            z, x=x, y=y, colorscale='Viridis', showscale=True
                        )
                        fig.write_image("correlation_heatmap.png", scale=2)
                        st.plotly_chart(fig, use_container_width=True)
                    else:
                        st.warning("âš  è¯·è‡³å°‘é€‰æ‹©ä¸¤åˆ—è¿›è¡Œç›¸å…³æ€§åˆ†æ")
                except Exception as e:
                    st.error(f"âŒ ç›¸å…³æ€§åˆ†æå¤±è´¥ Correlation Analysis Failed: {e}")

        # ========== âš–ï¸ åˆ†ç»„å¯¹æ¯”åˆ†æ Comparison Analysis ==========
        st.subheader("âš–ï¸ åˆ†ç»„å¯¹æ¯”åˆ†æ Comparison Analysis")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        compare_cols = df.select_dtypes(include=np.number).columns.tolist()
        category_cols = df.select_dtypes(exclude=np.number).columns.tolist()

        if category_cols and compare_cols:
            group_col = st.selectbox(
                "é€‰æ‹©åˆ†ç»„å˜é‡ï¼ˆç±»åˆ«å‹ï¼‰Select grouping categorical variable",
                category_cols,
                key=f"groupcol_{i}"
            )
            target_col = st.selectbox(
                "é€‰æ‹©å¯¹æ¯”çš„æ•°å€¼å˜é‡ Select numeric variable",
                compare_cols,
                key=f"targetcol_{i}"
            )

            graph_type = st.radio(
                "é€‰æ‹©å¯è§†åŒ–å›¾è¡¨ç±»å‹ Select Visualization Type",
                ["ç®±çº¿å›¾ Boxplot", "å°æç´å›¾ Violin Plot"],
                key=f"compare_graphtype_{i}"
            )

            if st.button(f"æ‰§è¡Œåˆ†ç»„å¯¹æ¯”åˆ†æ Run Comparison Dataset{i + 1}", key=f"compbtn_{i}"):
                group_values = df[group_col].dropna().unique()

                try:
                    # ç»Ÿè®¡æ£€éªŒéƒ¨åˆ†
                    if len(group_values) == 2:
                        # ä¸¤ç»„ -> tæ£€éªŒ
                        g1, g2 = group_values[:2]
                        data1 = df[df[group_col] == g1][target_col].dropna()
                        data2 = df[df[group_col] == g2][target_col].dropna()
                        t_stat, p_val = stats.ttest_ind(data1, data2, equal_var=False)
                        st.success(f"âœ… tæ£€éªŒç»“æœ: t={t_stat:.4f}, p={p_val:.4f}")
                    elif len(group_values) > 2:
                        # å¤šç»„ -> æ–¹å·®åˆ†æ
                        groups = [df[df[group_col] == g][target_col].dropna() for g in group_values]
                        f_stat, p_val = stats.f_oneway(*groups)
                        st.success(f"âœ… æ–¹å·®åˆ†æANOVAç»“æœ: F={f_stat:.4f}, p={p_val:.4f}")
                    else:
                        st.warning("âš  åˆ†ç»„æ•°é‡ä¸è¶³ï¼Œæ— æ³•è¿›è¡Œç»Ÿè®¡åˆ†æ")

                    # å¯è§†åŒ–éƒ¨åˆ†
                    if graph_type == "ç®±çº¿å›¾ Boxplot":
                        fig = px.box(
                            df, x=group_col, y=target_col, points="all",
                            title="ğŸ“¦ åˆ†ç»„ç®±çº¿å›¾ Boxplot",
                            labels={group_col: "åˆ†ç»„ Group", target_col: "æ•°å€¼ Value"}
                        )
                    else:
                        fig = px.violin(
                            df, x=group_col, y=target_col, points="all", box=True,
                            title="ğŸ» åˆ†ç»„å°æç´å›¾ Violin Plot",
                            labels={group_col: "åˆ†ç»„ Group", target_col: "æ•°å€¼ Value"}
                        )

                    st.plotly_chart(fig, use_container_width=True)

                except Exception as e:
                    st.error(f"âŒ åˆ†ç»„å¯¹æ¯”åˆ†æå¤±è´¥ Error: {e}")

        # ========== ğŸ§ª éå‚æ•°æ£€éªŒ Non-Parametric Test ========== #
        st.subheader("ğŸ§ª éå‚æ•°æ£€éªŒ Non-Parametric Test")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        np_category_cols = df.select_dtypes(exclude=np.number).columns.tolist()
        np_numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

        if np_category_cols and np_numeric_cols:
            np_group_col = st.selectbox(
                "é€‰æ‹©åˆ†ç»„å˜é‡ï¼ˆç±»åˆ«å‹ï¼‰Select Grouping Categorical Variable",
                np_category_cols,
                key=f"np_group_col_{i}"
            )

            np_target_col = st.selectbox(
                "é€‰æ‹©æ£€éªŒçš„æ•°å€¼å˜é‡ Select Target Numeric Variable",
                np_numeric_cols,
                key=f"np_target_col_{i}"
            )

            np_test_method = st.radio(
                "é€‰æ‹©æ£€éªŒæ–¹æ³• Select Test Method",
                ["Mann-Whitney Uæ£€éªŒï¼ˆä¸¤ç»„ï¼‰", "Kruskal-Wallisæ£€éªŒï¼ˆå¤šç»„ï¼‰"],
                key=f"np_test_method_{i}"
            )

            if st.button(f"æ‰§è¡Œéå‚æ•°æ£€éªŒ Run Non-Parametric Test Dataset{i + 1}", key=f"np_test_run_{i}"):
                try:
                    group_values = df[np_group_col].dropna().unique()

                    if np_test_method == "Mann-Whitney Uæ£€éªŒï¼ˆä¸¤ç»„ï¼‰":
                        if len(group_values) == 2:
                            g1, g2 = group_values[:2]
                            data1 = df[df[np_group_col] == g1][np_target_col].dropna()
                            data2 = df[df[np_group_col] == g2][np_target_col].dropna()

                            from scipy.stats import mannwhitneyu

                            u_stat, p_val = mannwhitneyu(data1, data2, alternative="two-sided")
                            st.success(f"âœ… Mann-Whitney Uæ£€éªŒç»“æœ: U={u_stat:.4f}, p={p_val:.4f}")
                        else:
                            st.warning("âš  å½“å‰é€‰æ‹©çš„åˆ†ç»„æ•°é‡ä¸æ˜¯2ç»„ï¼Œæ— æ³•è¿›è¡ŒMann-Whitney Uæ£€éªŒ")
                    else:
                        from scipy.stats import kruskal

                        if len(group_values) >= 2:
                            samples = [df[df[np_group_col] == g][np_target_col].dropna() for g in group_values]
                            h_stat, p_val = kruskal(*samples)
                            st.success(f"âœ… Kruskal-Wallisæ£€éªŒç»“æœ: H={h_stat:.4f}, p={p_val:.4f}")
                        else:
                            st.warning("âš  å½“å‰åˆ†ç»„ä¸è¶³ä¸¤ç»„ï¼Œæ— æ³•è¿›è¡ŒKruskal-Wallisæ£€éªŒ")

                    # å¯è§†åŒ–åˆ†å¸ƒ
                    import plotly.express as px

                    fig = px.box(
                        df,
                        x=np_group_col,
                        y=np_target_col,
                        points="all",
                        title="ğŸ“¦ åˆ†ç»„å˜é‡ä¸æ•°å€¼å˜é‡å…³ç³» Boxplot of Groups",
                        labels={np_group_col: "åˆ†ç»„å˜é‡ Group", np_target_col: "æ•°å€¼å˜é‡ Value"}
                    )
                    st.plotly_chart(fig, use_container_width=True)

                except Exception as e:
                    st.error(f"âŒ éå‚æ•°æ£€éªŒå¤±è´¥ Non-Parametric Test Failed: {e}")

        # ========== ğŸ“ˆ æ¯”ç‡å¢é•¿åˆ†æ Ratio Growth Analysisï¼ˆä¸“ä¸šç‰ˆï¼‰ ========== #
        st.subheader("ğŸ“ˆ æ¯”ç‡å¢é•¿åˆ†æï¼ˆä¸“ä¸šç‰ˆï¼‰Ratio Growth Analysis (Pro)")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        year_cols = df.select_dtypes(include=['int', 'float', 'object']).columns.tolist()
        value_cols = df.select_dtypes(include=np.number).columns.tolist()

        if year_cols and value_cols:
            time_col = st.selectbox(
                "é€‰æ‹©æ—¶é—´åˆ—ï¼ˆå¦‚å¹´ä»½ï¼‰Select Time Column",
                year_cols,
                key=f"timecol_{i}"
            )
            value_col = st.selectbox(
                "é€‰æ‹©æ•°å€¼åˆ—ï¼ˆç”¨äºè®¡ç®—å¢é•¿ç‡ï¼‰Select Value Column",
                value_cols,
                key=f"valuecol_{i}"
            )

            if st.button(f"æ‰§è¡Œä¸“ä¸šç‰ˆæ¯”ç‡å¢é•¿åˆ†æ Run Pro Ratio Analysis Dataset{i + 1}", key=f"ratioprobnt_{i}"):
                try:
                    df_ratio = df[[time_col, value_col]].dropna()
                    df_ratio[time_col] = pd.to_numeric(df_ratio[time_col], errors="coerce")
                    df_ratio = df_ratio.dropna().sort_values(by=time_col)

                    df_ratio["å¢é•¿ç‡ YoY Growth (%)"] = df_ratio[value_col].pct_change() * 100
                    df_ratio["å¢é•¿å€æ•° Growth Factor"] = df_ratio[value_col] / df_ratio[value_col].shift(1)

                    st.success("âœ… æ¯”ç‡åˆ†æï¼ˆä¸“ä¸šç‰ˆï¼‰å®Œæˆï¼Ratio Analysis Completed")
                    st.dataframe(df_ratio)

                    # -- æŠ˜çº¿å›¾ï¼šåŸå§‹æ•°å€¼å˜åŒ–è¶‹åŠ¿
                    fig_trend = px.line(
                        df_ratio,
                        x=time_col,
                        y=value_col,
                        markers=True,
                        title="ğŸ“ˆ æ•°å€¼å˜åŒ–è¶‹åŠ¿ Value Trend Over Time",
                        labels={time_col: "æ—¶é—´ Time", value_col: "æ•°å€¼ Value"}
                    )
                    st.plotly_chart(fig_trend, use_container_width=True)

                    # -- æŸ±çŠ¶å›¾ï¼šå¢é•¿ç‡å˜åŒ–
                    fig_growth = px.bar(
                        df_ratio,
                        x=time_col,
                        y="å¢é•¿ç‡ YoY Growth (%)",
                        color=df_ratio["å¢é•¿ç‡ YoY Growth (%)"] > 0,
                        color_discrete_map={True: "green", False: "red"},
                        title="ğŸ“Š å¹´å¢é•¿ç‡å˜åŒ– YoY Growth (%) Over Time",
                        labels={time_col: "æ—¶é—´ Time", "å¢é•¿ç‡ YoY Growth (%)": "å¢é•¿ç‡ YoY Growth (%)"},
                        text_auto=".2f"
                    )
                    st.plotly_chart(fig_growth, use_container_width=True)

                    st.info("âœ… ç»¿è‰²ä¸ºæ­£å¢é•¿ï¼Œçº¢è‰²ä¸ºè´Ÿå¢é•¿")

                except Exception as e:
                    st.error(f"âŒ æ¯”ç‡åˆ†æå¤±è´¥ Error: {e}")

        # ========== ğŸŒˆ ä¸»æˆåˆ†åˆ†æï¼ˆPCAä¸“ä¸šç‰ˆï¼‰Principal Component Analysis (Pro) ========== #
        st.subheader("ğŸŒˆ ä¸»æˆåˆ†åˆ†æï¼ˆä¸“ä¸šç‰ˆï¼‰PCA Analysis (Professional Version)")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        pca_cols = df.select_dtypes(include=np.number).columns.tolist()
        if pca_cols:
            selected_pca_cols = st.multiselect(
                "é€‰æ‹©ç”¨äºPCAçš„æ•°å€¼å­—æ®µ Select numeric fields for PCA",
                pca_cols,
                key=f"pca_cols_{i}"
            )
            pca_n_components = st.slider(
                "é€‰æ‹©ä¸»æˆåˆ†æ•°é‡ Number of Principal Components",
                min_value=2,
                max_value=min(len(selected_pca_cols), 10),
                value=2,
                key=f"pca_ncomp_{i}"
            )

            color_options = ["æ—  No Coloring"] + df.select_dtypes(exclude=np.number).columns.tolist()
            pca_color_col = st.selectbox(
                "é€‰æ‹©åˆ†ç±»ä¸Šè‰²å­—æ®µï¼ˆå¯é€‰ï¼‰Color by Category (Optional)",
                color_options,
                key=f"pca_colorcol_{i}"
            )

            if st.button(f"æ‰§è¡Œä¸“ä¸šç‰ˆPCAåˆ†æ Run Pro PCA Dataset{i + 1}", key=f"pca_run_{i}"):
                try:
                    from sklearn.decomposition import PCA
                    from sklearn.preprocessing import StandardScaler

                    X_raw = df[selected_pca_cols].dropna()
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X_raw)

                    pca = PCA(n_components=pca_n_components)
                    components = pca.fit_transform(X_scaled)

                    # è§£é‡Šæ–¹å·®è´¡çŒ®ç‡
                    explained_var = pca.explained_variance_ratio_

                    explained_df = pd.DataFrame({
                        "ä¸»æˆåˆ† Principal Component": [f"PC{i + 1}" for i in range(len(explained_var))],
                        "æ–¹å·®è´¡çŒ®ç‡ Explained Variance Ratio": explained_var
                    })

                    st.markdown("**ğŸ“Š ä¸»æˆåˆ†è´¡çŒ®ç‡ Explained Variance Ratio:**")
                    st.dataframe(explained_df)

                    fig_var = px.bar(
                        explained_df,
                        x="ä¸»æˆåˆ† Principal Component",
                        y="æ–¹å·®è´¡çŒ®ç‡ Explained Variance Ratio",
                        title="ğŸ“ˆ ä¸»æˆåˆ†è´¡çŒ®ç‡å›¾ Explained Variance of Components",
                        text_auto=".2%",
                        labels={"æ–¹å·®è´¡çŒ®ç‡ Explained Variance Ratio": "è´¡çŒ®ç‡ Explained Variance"}
                    )
                    st.plotly_chart(fig_var, use_container_width=True)

                    # -- PCAæ•£ç‚¹å¯è§†åŒ–
                    df_pca_plot = pd.DataFrame(components, columns=[f"PC{i + 1}" for i in range(pca_n_components)])
                    df_pca_plot["Sample Index"] = X_raw.index.astype(str)

                    if pca_color_col != "æ—  No Coloring" and pca_color_col in df.columns:
                        df_pca_plot["Color"] = df.loc[X_raw.index, pca_color_col].astype(str)
                    else:
                        df_pca_plot["Color"] = "All"

                    if pca_n_components == 2:
                        fig_pca2d = px.scatter(
                            df_pca_plot,
                            x="PC1", y="PC2",
                            color="Color",
                            title="ğŸŒˆ PCA 2Dé™ç»´æ•£ç‚¹å›¾ (æŒ‰åˆ†ç±»ç€è‰²) PCA 2D Scatter",
                            hover_data=["Sample Index"],
                            labels={"PC1": "ä¸»æˆåˆ†1 PC1", "PC2": "ä¸»æˆåˆ†2 PC2"}
                        )
                        st.plotly_chart(fig_pca2d, use_container_width=True)
                    elif pca_n_components >= 3:
                        fig_pca3d = px.scatter_3d(
                            df_pca_plot,
                            x="PC1", y="PC2", z="PC3",
                            color="Color",
                            title="ğŸŒˆ PCA 3Dé™ç»´æ•£ç‚¹å›¾ (æŒ‰åˆ†ç±»ç€è‰²) PCA 3D Scatter",
                            hover_data=["Sample Index"],
                            labels={"PC1": "ä¸»æˆåˆ†1 PC1", "PC2": "ä¸»æˆåˆ†2 PC2", "PC3": "ä¸»æˆåˆ†3 PC3"}
                        )
                        st.plotly_chart(fig_pca3d, use_container_width=True)

                    st.success("âœ… ä¸“ä¸šç‰ˆPCAé™ç»´åˆ†æå®Œæˆ PCA Analysis Completed!")

                except Exception as e:
                    st.error(f"âŒ PCAé™ç»´åˆ†æå¤±è´¥ PCA Failed: {e}")

        # ========== ğŸ§¬ Logisticå›å½’é£é™©é¢„æµ‹ï¼ˆå¯è§†åŒ–ç‰ˆï¼‰Logistic Regression with Visualization ========== #
        st.subheader("ğŸ§¬ Logisticå›å½’é£é™©é¢„æµ‹ï¼ˆå¯è§†åŒ–ç‰ˆï¼‰Logistic Regression Risk Prediction with Visualization")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        logistic_features = st.multiselect(
            "é€‰æ‹©ç‰¹å¾åˆ— Select Features",
            df.select_dtypes(include=np.number).columns.tolist(),
            key=f"logistic_features_{i}"
        )

        logistic_target = st.selectbox(
            "é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆ0/1äºŒåˆ†ç±»ï¼‰Select Target (Binary)",
            [col for col in df.columns if df[col].nunique() == 2],
            key=f"logistic_target_{i}"
        )

        if logistic_features and logistic_target:
            if st.button(f"æ‰§è¡ŒLogisticå›å½’é¢„æµ‹ Run Logistic Regression Dataset{i + 1}", key=f"logistic_run_{i}"):
                try:
                    from sklearn.linear_model import LogisticRegression
                    from sklearn.model_selection import train_test_split
                    from sklearn.metrics import roc_curve, auc, confusion_matrix, ConfusionMatrixDisplay

                    X = df[logistic_features].dropna()
                    y = df.loc[X.index, logistic_target]

                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                    model = LogisticRegression(max_iter=1000)
                    model.fit(X_train, y_train)

                    # --- ç³»æ•°åˆ†æ ---
                    coef_df = pd.DataFrame({
                        "Feature": logistic_features,
                        "Coefficient": model.coef_[0]
                    }).sort_values(by="Coefficient", ascending=False)

                    st.markdown("**ğŸ“Š å›å½’ç³»æ•°ï¼ˆå½±å“æ–¹å‘ä¸å¤§å°ï¼‰Logistic Regression Coefficients:**")
                    fig_coef = px.bar(
                        coef_df,
                        x="Coefficient",
                        y="Feature",
                        orientation="h",
                        title="ğŸ§¬ Logisticå›å½’ç³»æ•°æ¡å½¢å›¾",
                        labels={"Coefficient": "å›å½’ç³»æ•° Coefficient", "Feature": "ç‰¹å¾ Feature"}
                    )
                    st.plotly_chart(fig_coef, use_container_width=True)

                    # --- ROCæ›²çº¿ ---
                    y_pred_prob = model.predict_proba(X_test)[:, 1]

                    fpr, tpr, thresholds = roc_curve(y_test, y_pred_prob)
                    roc_auc = auc(fpr, tpr)

                    fig_roc = px.area(
                        x=fpr, y=tpr,
                        title=f"ğŸ©º ROCæ›²çº¿ (AUC = {roc_auc:.4f})",
                        labels=dict(x="å‡é˜³æ€§ç‡ FPR", y="çœŸæ­£ç‡ TPR")
                    )
                    fig_roc.write_image("logistic_roc_curve.png", scale=2)
                    fig_roc.add_shape(
                        type="line", line=dict(dash="dash"),
                        x0=0, x1=1, y0=0, y1=1
                    )
                    st.plotly_chart(fig_roc, use_container_width=True)

                    # --- æ··æ·†çŸ©é˜µ ---
                    y_pred = (y_pred_prob >= 0.5).astype(int)
                    cm = confusion_matrix(y_test, y_pred)
                    cm_df = pd.DataFrame(cm, index=["å®é™… 0", "å®é™… 1"], columns=["é¢„æµ‹ 0", "é¢„æµ‹ 1"])

                    st.markdown("**ğŸ¯ æ··æ·†çŸ©é˜µ Confusion Matrix:**")
                    st.dataframe(cm_df)

                    st.success(f"âœ… Logisticå›å½’å®Œæˆï¼ŒAUC = {roc_auc:.4f}")

                except Exception as e:
                    st.error(f"âŒ Logisticå›å½’å¤±è´¥ Logistic Regression Failed: {e}")

        # ========== ğŸ§¬ ç‰¹å¾é€‰æ‹©ï¼ˆLASSO / é€’å½’ç‰¹å¾æ¶ˆé™¤ RFEï¼‰Feature Selection ========== #
        st.subheader("ğŸ§¬ ç‰¹å¾é€‰æ‹©ï¼ˆLASSOå›å½’ / RFEé€’å½’ç‰¹å¾æ¶ˆé™¤ï¼‰Feature Selection (LASSO / RFE)")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        feature_numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

        if feature_numeric_cols:
            fs_target_col = st.selectbox(
                "é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆTarget Variableï¼‰",
                feature_numeric_cols,
                key=f"fs_target_col_{i}"
            )

            fs_feature_cols = st.multiselect(
                "é€‰æ‹©å€™é€‰ç‰¹å¾åˆ—ï¼ˆFeature Candidatesï¼‰",
                [col for col in feature_numeric_cols if col != fs_target_col],
                key=f"fs_feature_cols_{i}"
            )

            fs_method = st.radio(
                "é€‰æ‹©ç‰¹å¾é€‰æ‹©æ–¹æ³• Select Feature Selection Method",
                ["LASSOå›å½’ï¼ˆL1æ­£åˆ™åŒ–ï¼‰", "é€’å½’ç‰¹å¾æ¶ˆé™¤ RFE"],
                key=f"fs_method_{i}"
            )

            if fs_feature_cols and fs_target_col:
                if st.button(f"æ‰§è¡Œç‰¹å¾é€‰æ‹© Run Feature Selection Dataset{i + 1}", key=f"fs_run_{i}"):
                    try:
                        X = df[fs_feature_cols].dropna()
                        y = df.loc[X.index, fs_target_col]

                        # ç‰¹å¾é€‰æ‹©æ–¹æ³•
                        if fs_method == "LASSOå›å½’ï¼ˆL1æ­£åˆ™åŒ–ï¼‰":
                            from sklearn.linear_model import LassoCV

                            model = LassoCV(cv=5, random_state=42)
                            model.fit(X, y)

                            selected_features = [feature for feature, coef in zip(fs_feature_cols, model.coef_) if
                                                 abs(coef) > 1e-4]
                            st.success(f"âœ… LASSOé€‰æ‹©äº†{len(selected_features)}ä¸ªé‡è¦ç‰¹å¾ Features Selected by LASSO")
                            st.write("é€‰æ‹©çš„ç‰¹å¾ Selected Features:", selected_features)

                            # å¯è§†åŒ–ç‰¹å¾ç³»æ•°
                            import plotly.express as px

                            coef_df = pd.DataFrame({"Feature": fs_feature_cols, "Coefficient": model.coef_})
                            fig_coef = px.bar(
                                coef_df.sort_values(by="Coefficient"),
                                x="Coefficient", y="Feature",
                                orientation="h",
                                title="ğŸ§¬ LASSOç‰¹å¾ç³»æ•° LASSO Feature Coefficients",
                                text_auto=".2f"
                            )
                            fig_coef.update_layout(yaxis={'categoryorder': 'total ascending'})
                            st.plotly_chart(fig_coef, use_container_width=True)

                        else:  # RFE
                            from sklearn.linear_model import LogisticRegression
                            from sklearn.feature_selection import RFE

                            estimator = LogisticRegression(max_iter=1000, solver='liblinear')
                            selector = RFE(estimator, n_features_to_select=max(1, int(len(fs_feature_cols) * 0.5)))
                            selector = selector.fit(X, y)

                            selected_features = [feature for feature, support in zip(fs_feature_cols, selector.support_)
                                                 if support]
                            st.success(f"âœ… RFEé€‰æ‹©äº†{len(selected_features)}ä¸ªé‡è¦ç‰¹å¾ Features Selected by RFE")
                            st.write("é€‰æ‹©çš„ç‰¹å¾ Selected Features:", selected_features)

                            # å¯è§†åŒ–æ”¯æŒæƒ…å†µ
                            support_df = pd.DataFrame({
                                "Feature": fs_feature_cols,
                                "Selected (1=Yes, 0=No)": selector.support_.astype(int)
                            })
                            fig_rfe = px.bar(
                                support_df.sort_values(by="Selected (1=Yes, 0=No)"),
                                x="Selected (1=Yes, 0=No)",
                                y="Feature",
                                orientation="h",
                                title="ğŸ§¬ RFEç‰¹å¾é€‰æ‹©æƒ…å†µ RFE Feature Support",
                                text_auto=True
                            )
                            st.plotly_chart(fig_rfe, use_container_width=True)

                    except Exception as e:
                        st.error(f"âŒ ç‰¹å¾é€‰æ‹©å¤±è´¥ Feature Selection Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾åˆ—")
        else:
            st.info("âš  å½“å‰æ•°æ®é›†æ²¡æœ‰è¶³å¤Ÿçš„æ•°å€¼å‹å­—æ®µè¿›è¡Œç‰¹å¾é€‰æ‹©")

        # ========= ğŸŒ³ å†³ç­–æ ‘ä¸éšæœºæ£®æ—å»ºæ¨¡ Decision Tree & Random Forest ==========
        st.subheader("ğŸŒ³ å†³ç­–æ ‘ä¸éšæœºæ£®æ—å»ºæ¨¡ Decision Tree & Random Forest")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        tree_target = st.selectbox(
            f"é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆå› å˜é‡ï¼‰Dataset{i+1}",
            df.columns.tolist(),
            key=f"tree_target_{i}"
        )

        tree_features = st.multiselect(
            f"é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆè‡ªå˜é‡ï¼‰Dataset{i+1}",
            [col for col in df.columns if col != tree_target],
            key=f"tree_features_{i}"
        )

        tree_model_type = st.radio(
            f"é€‰æ‹©å»ºæ¨¡ç±»å‹ Dataset{i+1}",
            ["å†³ç­–æ ‘ Decision Tree", "éšæœºæ£®æ— Random Forest"],
            key=f"tree_model_type_{i}"
        )

        if st.button(f"æ‰§è¡Œæ ‘æ¨¡å‹å»ºæ¨¡ Run Tree Modeling Dataset{i+1}", key=f"tree_run_{i}"):
            try:
                from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
                from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
                from sklearn.model_selection import train_test_split
                from sklearn.metrics import accuracy_score, r2_score

                X = df[tree_features].dropna()
                y = df.loc[X.index, tree_target].dropna()
                X = X.loc[y.index]

                X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

                is_classification = y.nunique() <= 10 and y.dtype.name in ["object", "category", "bool", "int64"]

                if tree_model_type == "å†³ç­–æ ‘ Decision Tree":
                    model = DecisionTreeClassifier(random_state=42) if is_classification else DecisionTreeRegressor(random_state=42)
                else:
                    model = RandomForestClassifier(n_estimators=100, random_state=42) if is_classification else RandomForestRegressor(n_estimators=100, random_state=42)

                model.fit(X_train, y_train)
                y_pred = model.predict(X_test)

                if is_classification:
                    acc = accuracy_score(y_test, y_pred)
                    st.success(f"âœ… åˆ†ç±»å‡†ç¡®ç‡ Accuracy: {acc:.4f}")
                else:
                    r2 = r2_score(y_test, y_pred)
                    st.success(f"âœ… å›å½’RÂ²åˆ†æ•° RÂ² Score: {r2:.4f}")

                # ç‰¹å¾é‡è¦æ€§å›¾
                st.markdown("**ğŸ“Š ç‰¹å¾é‡è¦æ€§ Feature Importance**")
                importances = pd.Series(model.feature_importances_, index=tree_features)
                importances = importances.sort_values(ascending=False)
                st.bar_chart(importances)

            except Exception as e:
                st.error(f"âŒ æ ‘æ¨¡å‹å»ºæ¨¡å¤±è´¥ Tree Modeling Failed: {e}")

# ========== ğŸŒŸ XGBoostå»ºæ¨¡ï¼ˆä¸“ä¸šç‰ˆå¯è§†åŒ–ï¼‰XGBoost Modeling (Advanced Visualization) ========== #
        st.subheader("ğŸŒŸ XGBoostå»ºæ¨¡ï¼ˆä¸“ä¸šç‰ˆå¯è§†åŒ–ï¼‰XGBoost Modeling (Advanced Visualization)")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        xgb_target = st.selectbox(
            "é€‰æ‹©ç›®æ ‡åˆ—ï¼ˆå› å˜é‡ï¼‰Select Target Variable",
            df.select_dtypes(include=np.number).columns.tolist(),
            key=f"xgb_target_{i}"
        )

        xgb_features = st.multiselect(
            "é€‰æ‹©ç‰¹å¾åˆ—ï¼ˆè‡ªå˜é‡ï¼‰Select Feature Columns",
            [col for col in df.select_dtypes(include=np.number).columns if col != xgb_target],
            key=f"xgb_features_{i}"
        )

        if xgb_features and xgb_target:
            xgb_model_type = st.radio(
                "é€‰æ‹©å»ºæ¨¡ç±»å‹ Select Model Type",
                ["XGBoostå›å½’ XGBoost Regressor", "XGBooståˆ†ç±» XGBoost Classifier"],
                key=f"xgb_model_type_{i}"
            )

            xgb_max_depth = st.slider("æœ€å¤§æ ‘æ·±åº¦ Max Depth", 2, 10, 4, key=f"xgb_max_depth_{i}")
            xgb_learning_rate = st.slider("å­¦ä¹ ç‡ Learning Rate", 0.01, 0.5, 0.1, step=0.01,
                                          key=f"xgb_learning_rate_{i}")

            if st.button(f"æ‰§è¡ŒXGBoostå»ºæ¨¡ Run XGBoost Modeling Dataset{i + 1}", key=f"xgb_run_{i}"):
                try:
                    from xgboost import XGBRegressor, XGBClassifier
                    from sklearn.model_selection import train_test_split
                    from sklearn.metrics import mean_squared_error, accuracy_score, confusion_matrix, roc_curve, auc

                    X = df[xgb_features].dropna()
                    y = df.loc[X.index, xgb_target]
                    X = X.loc[y.index]

                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

                    if xgb_model_type == "XGBoostå›å½’ XGBoost Regressor":
                        model = XGBRegressor(max_depth=xgb_max_depth, learning_rate=xgb_learning_rate, n_estimators=100)
                        model.fit(X_train, y_train)
                        y_pred = model.predict(X_test)

                        rmse = mean_squared_error(y_test, y_pred, squared=False)
                        st.success(f"âœ… XGBoostå›å½’å®Œæˆï¼æµ‹è¯•é›†RMSE = {rmse:.4f}")

                        # å¯è§†åŒ–æ‹Ÿåˆæ•ˆæœ
                        st.markdown("**ğŸ“ˆ é¢„æµ‹å€¼ vs å®é™…å€¼ Predicted vs Actual:**")
                        fig_pred_actual = px.scatter(
                            x=y_test, y=y_pred,
                            labels={"x": "å®é™…å€¼ Actual", "y": "é¢„æµ‹å€¼ Predicted"},
                            title="ğŸ“ˆ é¢„æµ‹å€¼ vs å®é™…å€¼æ•£ç‚¹å›¾"
                        )
                        fig_pred_actual.add_shape(
                            type="line", line=dict(dash="dash"),
                            x0=y_test.min(), y0=y_test.min(),
                            x1=y_test.max(), y1=y_test.max()
                        )
                        st.plotly_chart(fig_pred_actual, use_container_width=True)

                    else:
                        model = XGBClassifier(max_depth=xgb_max_depth, learning_rate=xgb_learning_rate,
                                              n_estimators=100)
                        model.fit(X_train, y_train)
                        y_pred = model.predict(X_test)

                        acc = accuracy_score(y_test, y_pred)
                        st.success(f"âœ… XGBooståˆ†ç±»å®Œæˆï¼æµ‹è¯•é›†å‡†ç¡®ç‡ Accuracy = {acc:.4f}")

                        # æ··æ·†çŸ©é˜µ
                        cm = confusion_matrix(y_test, y_pred)
                        cm_df = pd.DataFrame(cm, index=["å®é™… 0", "å®é™… 1"], columns=["é¢„æµ‹ 0", "é¢„æµ‹ 1"])
                        st.markdown("**ğŸ¯ æ··æ·†çŸ©é˜µ Confusion Matrix:**")
                        st.dataframe(cm_df)

                        # ROCæ›²çº¿
                        y_pred_prob = model.predict_proba(X_test)[:, 1]
                        fpr, tpr, _ = roc_curve(y_test, y_pred_prob)
                        roc_auc = auc(fpr, tpr)

                        fig_roc = px.area(
                            x=fpr, y=tpr,
                            title=f"ğŸ©º ROCæ›²çº¿ (AUC = {roc_auc:.4f})",
                            labels=dict(x="å‡é˜³æ€§ç‡ FPR", y="çœŸæ­£ç‡ TPR")
                        )
                        fig_roc.add_shape(
                            type="line", line=dict(dash="dash"),
                            x0=0, x1=1, y0=0, y1=1
                        )
                        st.plotly_chart(fig_roc, use_container_width=True)

                    # ç‰¹å¾é‡è¦æ€§
                    st.markdown("**ğŸ“Š ç‰¹å¾é‡è¦æ€§ Feature Importance:**")
                    feature_importance = pd.Series(model.feature_importances_, index=xgb_features)
                    feature_importance = feature_importance.sort_values(ascending=True)

                    fig_fi = px.bar(
                        feature_importance,
                        orientation='h',
                        labels={"value": "é‡è¦æ€§ Importance", "index": "ç‰¹å¾ Feature"},
                        title="ğŸ“Š XGBoostç‰¹å¾é‡è¦æ€§æ¡å½¢å›¾"
                    )
                    st.plotly_chart(fig_fi, use_container_width=True)

                except Exception as e:
                    st.error(f"âŒ XGBoostå»ºæ¨¡å¤±è´¥ Error: {e}")

# ========= ğŸ›¡ï¸ ç®€å•å¼‚å¸¸æ£€æµ‹ï¼ˆZ-Score/IQRæ³•ï¼‰Simple Outlier Detection ==========
        st.subheader("ğŸ›¡ï¸ ç®€å•å¼‚å¸¸æ£€æµ‹ Simple Outlier Detection")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        outlier_method = st.selectbox(
            f"é€‰æ‹©å¼‚å¸¸æ£€æµ‹æ–¹æ³• Dataset{i+1}",
            ["Z-Scoreæ–¹æ³•", "å››åˆ†ä½è·ï¼ˆIQRï¼‰æ³•"],
            key=f"outlier_method_{i}"
        )

        outlier_cols = st.multiselect(
            f"é€‰æ‹©è¦æ£€æµ‹çš„å­—æ®µ Dataset{i+1}",
            df.select_dtypes(include=np.number).columns.tolist(),
            key=f"outlier_cols_{i}"
        )

        if st.button(f"æ‰§è¡Œå¼‚å¸¸æ£€æµ‹ Run Outlier Detection Dataset{i+1}", key=f"outlier_run_{i}"):
            if outlier_cols:
                try:
                    df_outlier = df.copy()
                    found_outliers = False

                    if outlier_method == "Z-Scoreæ–¹æ³•":
                        for col in outlier_cols:
                            z_scores = np.abs(stats.zscore(df_outlier[col]))
                            is_outlier = z_scores > 3
                            df_outlier[f"{col}_å¼‚å¸¸æ ‡è®°"] = np.where(is_outlier, "å¼‚å¸¸", "æ­£å¸¸")
                            if is_outlier.any():
                                found_outliers = True
                    else:
                        for col in outlier_cols:
                            Q1 = df_outlier[col].quantile(0.25)
                            Q3 = df_outlier[col].quantile(0.75)
                            IQR = Q3 - Q1
                            lower = Q1 - 1.5 * IQR
                            upper = Q3 + 1.5 * IQR
                            is_outlier = (df_outlier[col] < lower) | (df_outlier[col] > upper)
                            df_outlier[f"{col}_å¼‚å¸¸æ ‡è®°"] = np.where(is_outlier, "å¼‚å¸¸", "æ­£å¸¸")
                            if is_outlier.any():
                                found_outliers = True

                    st.dataframe(df_outlier)

                    if found_outliers:
                        st.success("âœ… æ£€æµ‹åˆ°å¼‚å¸¸å€¼ Outliers Detected")
                    else:
                        st.info("æœªæ£€æµ‹åˆ°å¼‚å¸¸å€¼ No Outliers Found")
                except Exception as e:
                    st.error(f"âŒ å¼‚å¸¸æ£€æµ‹å¤±è´¥ Outlier Detection Failed: {e}")
            else:
                st.warning("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå­—æ®µè¿›è¡Œå¼‚å¸¸æ£€æµ‹")

# ========= ğŸ›¡ï¸ é«˜çº§å¼‚å¸¸æ£€æµ‹ï¼ˆIsolation Forest / LOFï¼‰Advanced Outlier Detection ==========
        st.subheader("ğŸ›¡ï¸ é«˜çº§è‡ªåŠ¨å¼‚å¸¸æ£€æµ‹ Advanced Outlier Detection")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        advanced_method = st.radio(
            f"é€‰æ‹©æ£€æµ‹ç®—æ³• Dataset{i+1}",
            ["Isolation Forest", "Local Outlier Factor (LOF)"],
            key=f"advanced_outlier_method_{i}"
        )

        advanced_cols = st.multiselect(
            f"é€‰æ‹©ç”¨äºæ£€æµ‹çš„ç‰¹å¾åˆ— Dataset{i+1}",
            df.select_dtypes(include=np.number).columns.tolist(),
            key=f"advanced_outlier_cols_{i}"
        )

        if st.button(f"æ‰§è¡Œé«˜çº§å¼‚å¸¸æ£€æµ‹ Run Advanced Detection Dataset{i+1}", key=f"advanced_outlier_run_{i}"):
            if advanced_cols:
                try:
                    from sklearn.ensemble import IsolationForest
                    from sklearn.neighbors import LocalOutlierFactor

                    X = df[advanced_cols].dropna()
                    X_index = X.index

                    if advanced_method == "Isolation Forest":
                        model = IsolationForest(contamination=0.05, random_state=42)
                        preds = model.fit_predict(X)
                        labels = np.where(preds == -1, "å¼‚å¸¸ Outlier", "æ­£å¸¸ Normal")
                    else:
                        model = LocalOutlierFactor(n_neighbors=20, contamination=0.05)
                        preds = model.fit_predict(X)
                        labels = np.where(preds == -1, "å¼‚å¸¸ Outlier", "æ­£å¸¸ Normal")

                    df_result = df.loc[X_index].copy()
                    df_result["é«˜çº§å¼‚å¸¸æ£€æµ‹ç»“æœ Detection Result"] = labels

                    st.success("âœ… é«˜çº§å¼‚å¸¸æ£€æµ‹å®Œæˆ Advanced Detection Completed")
                    st.dataframe(df_result)

                    n_outliers = np.sum(labels == "å¼‚å¸¸ Outlier")
                    st.info(f"æ£€æµ‹åˆ° {n_outliers} æ¡å¼‚å¸¸æ•°æ® Points detected as Outliers: {n_outliers}")
                except Exception as e:
                    st.error(f"âŒ é«˜çº§å¼‚å¸¸æ£€æµ‹å¤±è´¥ Advanced Detection Failed: {e}")
            else:
                st.warning("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾åˆ—")
# ========= ğŸ§  é«˜çº§PCAæ¨¡å—ï¼ˆå¸¦åˆ†ç±»ä¸Šè‰²ï¼‰Advanced PCA with Coloring ==========
        st.subheader("ğŸ§  é«˜çº§PCAé™ç»´åˆ†æ Advanced PCA with Coloring")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        pca_features = st.multiselect(
            f"é€‰æ‹©ç”¨äºPCAçš„æ•°å€¼ç‰¹å¾åˆ— Dataset{i+1}",
            df.select_dtypes(include=np.number).columns.tolist(),
            key=f"pca_features_{i}"
        )

        if pca_features:
            n_components = st.slider(
                f"é€‰æ‹©ä¸»æˆåˆ†æ•°é‡ Dataset{i+1}",
                min_value=2,
                max_value=min(5, len(pca_features)),
                value=2,
                key=f"pca_n_components_{i}"
            )

            color_options = ["æ—  No Coloring"] + df.select_dtypes(exclude=np.number).columns.tolist()
            color_col = st.selectbox(
                f"é€‰æ‹©ç”¨äºåˆ†ç±»ä¸Šè‰²çš„å­—æ®µï¼ˆå¯é€‰ï¼‰Dataset{i+1}",
                color_options,
                key=f"pca_color_col_{i}"
            )

            if st.button(f"æ‰§è¡Œé«˜çº§PCAåˆ†æ Run PCA Dataset{i+1}", key=f"pca_run_{i}"):
                try:
                    from sklearn.decomposition import PCA
                    from sklearn.preprocessing import StandardScaler

                    # æ ‡å‡†åŒ–æ•°æ®
                    X_raw = df[pca_features].dropna()
                    scaler = StandardScaler()
                    X_scaled = scaler.fit_transform(X_raw)

                    # æ‰§è¡ŒPCA
                    pca = PCA(n_components=n_components)
                    components = pca.fit_transform(X_scaled)

                    explained_var = pca.explained_variance_ratio_

                    explained_df = pd.DataFrame({
                        "ä¸»æˆåˆ† Principal Component": [f"PC{j+1}" for j in range(len(explained_var))],
                        "æ–¹å·®è´¡çŒ®ç‡ Explained Variance Ratio": explained_var
                    })
                    st.dataframe(explained_df)

                    df_pca_plot = pd.DataFrame(components, columns=[f"PC{j+1}" for j in range(n_components)])
                    df_pca_plot["æ ·æœ¬ç´¢å¼• Sample Index"] = X_raw.index.astype(str)

                    if color_col != "æ—  No Coloring" and color_col in df.columns:
                        df_pca_plot["Color"] = df.loc[X_raw.index, color_col].astype(str)
                    else:
                        df_pca_plot["Color"] = "All"

                    # å¯è§†åŒ–
                    if n_components == 2:
                        fig = px.scatter(
                            df_pca_plot,
                            x="PC1", y="PC2",
                            color="Color",
                            hover_data=["æ ·æœ¬ç´¢å¼• Sample Index"],
                            title="ğŸŒˆ é«˜çº§PCA 2Dé™ç»´å¯è§†åŒ–ï¼ˆåˆ†ç±»ä¸Šè‰²ï¼‰"
                        )
                        st.plotly_chart(fig, use_container_width=True)
                    elif n_components >= 3:
                        fig = px.scatter_3d(
                            df_pca_plot,
                            x="PC1", y="PC2", z="PC3",
                            color="Color",
                            hover_data=["æ ·æœ¬ç´¢å¼• Sample Index"],
                            title="ğŸŒˆ é«˜çº§PCA 3Dé™ç»´å¯è§†åŒ–ï¼ˆåˆ†ç±»ä¸Šè‰²ï¼‰"
                        )
                        st.plotly_chart(fig, use_container_width=True)

                    st.success("âœ… é«˜çº§PCAåˆ†æå®Œæˆ Advanced PCA Completed")
                except Exception as e:
                    st.error(f"âŒ PCAåˆ†æå¤±è´¥ PCA Failed: {e}")

# ========== ğŸŒ èšç±»åˆ†æï¼ˆKMeans / å±‚æ¬¡èšç±»ï¼‰Clustering Analysis (KMeans / Hierarchical) ========== #
        st.subheader("ğŸŒ èšç±»åˆ†æï¼ˆKMeans / å±‚æ¬¡èšç±»ï¼‰Clustering Analysis (KMeans / Hierarchical)")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        cluster_numeric_cols = df.select_dtypes(include=np.number).columns.tolist()

        if cluster_numeric_cols:
            cluster_features = st.multiselect(
                "é€‰æ‹©ç”¨äºèšç±»çš„æ•°å€¼å‹ç‰¹å¾åˆ— Select Features for Clustering",
                cluster_numeric_cols,
                key=f"cluster_features_{i}"
            )

            cluster_method = st.radio(
                "é€‰æ‹©èšç±»æ–¹æ³• Select Clustering Method",
                ["KMeansèšç±»", "å±‚æ¬¡èšç±» Hierarchical Clustering"],
                key=f"cluster_method_{i}"
            )

            if cluster_features:
                cluster_n_clusters = st.slider(
                    "é€‰æ‹©èšç±»ç°‡æ•° Number of Clusters",
                    min_value=2, max_value=10, value=3,
                    key=f"cluster_n_clusters_{i}"
                )

                if st.button(f"æ‰§è¡Œèšç±»åˆ†æ Run Clustering Dataset{i + 1}", key=f"cluster_run_{i}"):
                    try:
                        from sklearn.preprocessing import StandardScaler
                        from sklearn.cluster import KMeans, AgglomerativeClustering

                        X = df[cluster_features].dropna()
                        scaler = StandardScaler()
                        X_scaled = scaler.fit_transform(X)

                        if cluster_method == "KMeansèšç±»":
                            model = KMeans(n_clusters=cluster_n_clusters, random_state=42)
                            cluster_labels = model.fit_predict(X_scaled)
                            st.success("âœ… KMeansèšç±»å®Œæˆ Clustering Completed!")
                        else:
                            model = AgglomerativeClustering(n_clusters=cluster_n_clusters)
                            cluster_labels = model.fit_predict(X_scaled)
                            st.success("âœ… å±‚æ¬¡èšç±»å®Œæˆ Clustering Completed!")

                        # æ·»åŠ èšç±»æ ‡ç­¾
                        df_result = df.loc[X.index].copy()
                        df_result["Cluster_Label"] = cluster_labels
                        st.dataframe(df_result)

                        # å¯è§†åŒ–ï¼ˆ2Dæˆ–3Dï¼‰
                        import plotly.express as px

                        if len(cluster_features) >= 3:
                            fig_cluster = px.scatter_3d(
                                df_result,
                                x=cluster_features[0],
                                y=cluster_features[1],
                                z=cluster_features[2],
                                color="Cluster_Label",
                                title="ğŸŒ èšç±»ç»“æœ3Då¯è§†åŒ– Clustering Result (3D)",
                                labels={"Cluster_Label": "èšç±»ç°‡ Cluster"}
                            )
                            fig_cluster.write_image("cluster_plot.png", scale=2)
                        else:
                            fig_cluster = px.scatter(
                                df_result,
                                x=cluster_features[0],
                                y=cluster_features[1],
                                color="Cluster_Label",
                                title="ğŸŒ èšç±»ç»“æœ2Då¯è§†åŒ– Clustering Result (2D)",
                                labels={"Cluster_Label": "èšç±»ç°‡ Cluster"}
                            )
                            fig_cluster.write_image("cluster_plot.png", scale=2)
                        st.plotly_chart(fig_cluster, use_container_width=True)

                    except Exception as e:
                        st.error(f"âŒ èšç±»åˆ†æå¤±è´¥ Clustering Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸¤ä¸ªæ•°å€¼å‹ç‰¹å¾è¿›è¡Œèšç±»")
        else:
            st.info("âš  å½“å‰æ•°æ®é›†ä¸­æ²¡æœ‰è¶³å¤Ÿçš„æ•°å€¼å‹å­—æ®µè¿›è¡Œèšç±»åˆ†æ")

# ========== â³ æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆAuto-ARIMAä¸“ä¸šç‰ˆï¼‰Time Series Forecast (Advanced Version) ========== #
        st.subheader("â³ æ—¶é—´åºåˆ—é¢„æµ‹ï¼ˆAuto-ARIMAä¸“ä¸šç‰ˆï¼‰Time Series Forecast (Advanced Version)")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        ts_time_col = st.selectbox(
            "é€‰æ‹©æ—¶é—´åˆ— Select Time Column",
            df.select_dtypes(include=["int", "float", "object"]).columns.tolist(),
            key=f"time_col_ts_{i}"
        )

        ts_value_col = st.selectbox(
            "é€‰æ‹©æ•°å€¼åˆ— Select Value Column",
            df.select_dtypes(include=np.number).columns.tolist(),
            key=f"value_col_ts_{i}"
        )

        forecast_periods = st.number_input(
            "é¢„æµ‹æ­¥æ•°ï¼ˆæœªæ¥å‘¨æœŸæ•°ï¼‰Forecast Steps",
            min_value=1, max_value=50, value=5,
            key=f"forecast_periods_{i}"
        )

        if st.button(f"æ‰§è¡Œæ—¶é—´åºåˆ—é¢„æµ‹ Run Time Series Forecast Dataset{i + 1}", key=f"forecast_run_{i}"):
            try:
                import statsmodels.api as sm
                from pmdarima import auto_arima
                import plotly.graph_objects as go

                df_ts = df[[ts_time_col, ts_value_col]].dropna()
                df_ts[ts_time_col] = pd.to_numeric(df_ts[ts_time_col], errors='coerce')
                df_ts = df_ts.dropna().sort_values(by=ts_time_col)
                df_ts.set_index(ts_time_col, inplace=True)

                st.info("ğŸ” æ­£åœ¨å¯»æ‰¾æœ€ä½³ARIMAæ¨¡å‹ï¼Œè¯·ç¨å€™...")
                model = auto_arima(df_ts[ts_value_col], seasonal=False, trace=True, error_action='ignore',
                                   suppress_warnings=True)

                st.success(f"âœ… Auto-ARIMAå®Œæˆï¼ æœ€ä½³æ¨¡å‹: ARIMA{model.order}")
                st.markdown(f"- **AICå€¼**: {model.aic():.2f}")
                st.markdown(f"- **BICå€¼**: {model.bic():.2f}")

                forecast, conf_int = model.predict(n_periods=forecast_periods, return_conf_int=True)
                future_index = np.arange(df_ts.index.max() + 1, df_ts.index.max() + forecast_periods + 1)

                # ç»˜å›¾
                fig = go.Figure()

                # å†å²æ•°æ®
                fig.add_trace(go.Scatter(
                    x=df_ts.index,
                    y=df_ts[ts_value_col],
                    mode="lines",
                    name="å†å²æ•°æ® History"
                ))

                # é¢„æµ‹æ•°æ®
                fig.add_trace(go.Scatter(
                    x=future_index,
                    y=forecast,
                    mode="lines+markers",
                    name="é¢„æµ‹æ•°æ® Forecast"
                ))

                # ä¸Šä¸‹ç½®ä¿¡åŒºé—´
                fig.add_trace(go.Scatter(
                    x=np.concatenate([future_index, future_index[::-1]]),
                    y=np.concatenate([conf_int[:, 0], conf_int[::-1, 1]]),
                    fill="toself",
                    fillcolor="rgba(255, 0, 0, 0.2)",
                    line=dict(color="rgba(255,255,255,0)"),
                    hoverinfo="skip",
                    name="95%é¢„æµ‹åŒºé—´"
                ))

                fig.update_layout(
                    title="â³ æ—¶é—´åºåˆ—é¢„æµ‹ç»“æœï¼ˆå«95%ç½®ä¿¡åŒºé—´ï¼‰",
                    xaxis_title="æ—¶é—´ Time",
                    yaxis_title="å€¼ Value",
                    legend_title="å›¾ä¾‹ Legend",
                    template="plotly_white"
                )

                st.plotly_chart(fig, use_container_width=True)

            except Exception as e:
                st.error(f"âŒ æ—¶é—´åºåˆ—é¢„æµ‹å¤±è´¥ Error: {e}")
# ========== ğŸŒŸ ç”Ÿå­˜åˆ†æï¼ˆKaplan-Meierä¸“ä¸šç‰ˆï¼‰Kaplan-Meier Survival Analysis (Advanced Version) ========== #
        st.subheader("ğŸŒŸ ç”Ÿå­˜åˆ†æï¼ˆKaplan-Meierä¸“ä¸šç‰ˆï¼‰Kaplan-Meier Survival Analysis (Advanced Version)")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.select_dtypes(include=np.number).columns) >= 2:
            time_col = st.selectbox(
                "é€‰æ‹©ç”Ÿå­˜æ—¶é—´åˆ— Time-to-Event Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"survival_time_{i}"
            )
            event_col = st.selectbox(
                "é€‰æ‹©äº‹ä»¶çŠ¶æ€åˆ—ï¼ˆ0=æ— äº‹ä»¶ï¼Œ1=å‘ç”Ÿäº‹ä»¶ï¼‰Event Status Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"survival_event_{i}"
            )
            group_col = st.selectbox(
                "é€‰æ‹©åˆ†ç»„åˆ—ï¼ˆå¯é€‰ï¼‰Grouping Column (Optional)",
                ["æ— åˆ†ç»„ No Grouping"] + df.select_dtypes(exclude=np.number).columns.tolist(),
                key=f"survival_group_{i}"
            )

            show_ci = st.checkbox("æ˜¾ç¤ºç½®ä¿¡åŒºé—´ï¼ˆConfidence Intervalï¼‰", value=True, key=f"survival_show_ci_{i}")

            if st.button(f"æ‰§è¡Œç”Ÿå­˜åˆ†æ Run Survival Analysis Dataset{i + 1}", key=f"survival_run_{i}"):
                try:
                    from lifelines import KaplanMeierFitter
                    from lifelines.statistics import logrank_test
                    import matplotlib.pyplot as plt

                    T = df[time_col]
                    E = df[event_col]

                    fig, ax = plt.subplots()

                    if group_col == "æ— åˆ†ç»„ No Grouping":
                        kmf = KaplanMeierFitter()
                        kmf.fit(T, event_observed=E)
                        kmf.plot_survival_function(ax=ax, ci_show=show_ci)
                        st.success(f"âœ… ä¸­ä½ç”Ÿå­˜æ—¶é—´ Median Survival Time: {kmf.median_survival_time_:.2f}")
                    else:
                        groups = df[group_col].dropna().unique()
                        for g in groups:
                            ix = df[group_col] == g
                            kmf = KaplanMeierFitter()
                            kmf.fit(T[ix], event_observed=E[ix], label=str(g))
                            kmf.plot_survival_function(ax=ax, ci_show=show_ci)

                        if len(groups) == 2:
                            ix1 = df[group_col] == groups[0]
                            ix2 = df[group_col] == groups[1]
                            results = logrank_test(
                                T[ix1], T[ix2],
                                event_observed_A=E[ix1],
                                event_observed_B=E[ix2]
                            )
                            p_val = results.p_value
                            st.success(f"âœ… Log-rankæ£€éªŒå®Œæˆ På€¼: {p_val:.4f}")
                            if p_val < 0.05:
                                st.info("âœ… ç»„é—´ç”Ÿå­˜å·®å¼‚æ˜¾è‘— Significant Difference (p<0.05)")
                            else:
                                st.info("âš  ç»„é—´ç”Ÿå­˜å·®å¼‚ä¸æ˜¾è‘— No Significant Difference (pâ‰¥0.05)")
                        else:
                            st.info("âš  åˆ†ç»„è¶…è¿‡2ç»„ï¼Œæš‚ä¸æ”¯æŒè‡ªåŠ¨Log-rankæ£€éªŒï¼Œä»…å±•ç¤ºå„ç»„ç”Ÿå­˜æ›²çº¿")

                    plt.title("Kaplan-Meier ç”Ÿå­˜æ›²çº¿ Kaplan-Meier Survival Curve")
                    plt.xlabel("æ—¶é—´ Time")
                    plt.ylabel("ç”Ÿå­˜æ¦‚ç‡ Survival Probability")
                    plt.grid(True)
                    st.pyplot(fig)

                except Exception as e:
                    st.error(f"âŒ ç”Ÿå­˜åˆ†æå¤±è´¥ Survival Analysis Failed: {e}")

# ========== ğŸ§¬ Coxå›å½’ç”Ÿå­˜åˆ†æï¼ˆå¤šå› ç´ ç”Ÿå­˜å»ºæ¨¡ï¼‰Cox Proportional-Hazards Regression ========== #
        st.subheader("ğŸ§¬ Coxæ¯”ä¾‹é£é™©å›å½’ç”Ÿå­˜åˆ†æ Cox Proportional-Hazards Regression")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        # ç”Ÿå­˜æ—¶é—´åˆ— & äº‹ä»¶åˆ—ï¼ˆå¿…é¡»æ•°å€¼å‹ï¼‰
        surv_numeric_cols = df.select_dtypes(include=np.number).columns.tolist()
        surv_categorical_cols = df.select_dtypes(exclude=np.number).columns.tolist()

        if len(surv_numeric_cols) >= 2:
            cox_time_col = st.selectbox(
                "é€‰æ‹©ç”Ÿå­˜æ—¶é—´åˆ—ï¼ˆTime-to-Event Columnï¼‰",
                surv_numeric_cols,
                key=f"cox_time_col_{i}"
            )

            cox_event_col = st.selectbox(
                "é€‰æ‹©äº‹ä»¶çŠ¶æ€åˆ—ï¼ˆ0=æ— äº‹ä»¶ï¼Œ1=å‘ç”Ÿäº‹ä»¶ Event Status Columnï¼‰",
                surv_numeric_cols,
                key=f"cox_event_col_{i}"
            )

            # ç‰¹å¾é€‰æ‹©
            cox_features = st.multiselect(
                "é€‰æ‹©ç‰¹å¾å˜é‡ï¼ˆæ•°å€¼å‹å’Œç±»åˆ«å‹å‡å¯ï¼‰Select Predictor Features",
                df.columns.tolist(),
                key=f"cox_features_{i}"
            )

            if cox_features:
                if st.button(f"æ‰§è¡ŒCoxå›å½’åˆ†æ Run Cox Regression Dataset{i + 1}", key=f"cox_run_{i}"):
                    try:
                        from lifelines import CoxPHFitter

                        # æ„é€  Coxæ¨¡å‹æ•°æ®é›†
                        df_cox = df[[cox_time_col, cox_event_col] + cox_features].dropna()

                        # å°†åˆ†ç±»å˜é‡è½¬ä¸ºone-hotç¼–ç 
                        df_cox_encoded = pd.get_dummies(df_cox, columns=[col for col in cox_features if
                                                                         df[col].dtype == 'object' or df[
                                                                             col].dtype.name == 'category'])

                        # Coxå»ºæ¨¡
                        cph = CoxPHFitter()
                        cph.fit(df_cox_encoded, duration_col=cox_time_col, event_col=cox_event_col)

                        st.success("âœ… Coxå›å½’å»ºæ¨¡å®Œæˆ Cox Regression Completed!")
                        st.dataframe(cph.summary)

                        # å¯è§†åŒ–1: Hazard Ratios
                        import plotly.express as px

                        hr_plot_df = cph.summary.reset_index()
                        fig_hr = px.bar(
                            hr_plot_df,
                            x="exp(coef)",
                            y="index",
                            orientation="h",
                            title="ğŸ§¬ Hazard Ratios (HR) of Predictors",
                            labels={"index": "å˜é‡ Variable", "exp(coef)": "é£é™©æ¯” Hazard Ratio"},
                            text_auto=".2f"
                        )
                        fig_hr.update_layout(yaxis={'categoryorder': 'total ascending'})
                        st.plotly_chart(fig_hr, use_container_width=True)

                        # å¯è§†åŒ–2: ç”Ÿå­˜å‡½æ•°
                        st.markdown("### ğŸ“ˆ æ ·æœ¬æ•´ä½“ç”Ÿå­˜å‡½æ•° Estimated Survival Function")
                        fig_surv = cph.plot_survival_function()
                        st.pyplot(fig_surv.figure)

                    except Exception as e:
                        st.error(f"âŒ Coxå›å½’åˆ†æå¤±è´¥ Cox Regression Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªç‰¹å¾å˜é‡ç”¨äºCoxå›å½’å»ºæ¨¡")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦ä¸¤ä¸ªæ•°å€¼åˆ—ï¼ˆç”Ÿå­˜æ—¶é—´ + äº‹ä»¶çŠ¶æ€åˆ—ï¼‰")

# ========== ğŸ—ºï¸ GBDåœ°ç†åˆ†å¸ƒåˆ†æ Geographic Distribution Analysis ========== #
        st.subheader("ğŸ—ºï¸ GBDåœ°ç†åˆ†å¸ƒåˆ†æ Geographic Distribution")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.columns) >= 3:
            geo_country_col = st.selectbox(
                "é€‰æ‹©å›½å®¶/åœ°åŒºåˆ— Select Country/Region Column",
                df.columns.tolist(),
                key=f"geo_country_col_{i}"
            )

            geo_value_col = st.selectbox(
                "é€‰æ‹©è´Ÿæ‹…æ•°å€¼åˆ—ï¼ˆå¦‚DALYsã€æ­»äº¡ç‡ï¼‰Select Burden Value Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"geo_value_col_{i}"
            )

            selected_year_geo = st.selectbox(
                "é€‰æ‹©å¹´ä»½ï¼ˆå¦‚æœæœ‰ï¼‰Select Year",
                sorted(df[df.columns[df.columns.str.contains('year', case=False)]].iloc[:, 0].dropna().unique()) if any(
                    df.columns.str.contains('year', case=False)) else [],
                key=f"geo_selected_year_{i}"
            ) if any(df.columns.str.contains('year', case=False)) else None

            if st.button(f"ç»˜åˆ¶åœ°ç†åˆ†å¸ƒåœ°å›¾ Plot Geographic Distribution Dataset{i + 1}", key=f"geo_run_{i}"):
                try:
                    df_geo = df[[geo_country_col, geo_value_col]].dropna()

                    if selected_year_geo:
                        year_col_detected = df.columns[df.columns.str.contains('year', case=False)][0]
                        df_geo = df[df[year_col_detected] == selected_year_geo][
                            [geo_country_col, geo_value_col]].dropna()

                    import plotly.express as px

                    fig = px.choropleth(
                        df_geo,
                        locations=geo_country_col,
                        locationmode='country names',
                        color=geo_value_col,
                        title="ğŸ—ºï¸ å›½å®¶/åœ°åŒºè´Ÿæ‹…åˆ†å¸ƒåœ°å›¾ Country/Region Burden Distribution",
                        color_continuous_scale="Plasma"
                    )
                    st.plotly_chart(fig, use_container_width=True)

                except Exception as e:
                    st.error(f"âŒ åœ°ç†åˆ†å¸ƒç»˜åˆ¶å¤±è´¥ Geographic Plot Failed: {e}")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦å›½å®¶åˆ—å’Œæ•°å€¼åˆ—")

# ========== ğŸ“ˆ GBDè´Ÿæ‹…éšæ—¶é—´å˜åŒ–è¶‹åŠ¿åˆ†æï¼ˆç»Ÿä¸€ç‰ˆï¼‰GBD Burden Trend Analysis ========== #
        st.subheader("ğŸ“ˆ GBDè´Ÿæ‹…éšæ—¶é—´å˜åŒ–è¶‹åŠ¿åˆ†æ Burden Trend Over Time")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.columns) >= 3:
            trend_time_col = st.selectbox(
                "é€‰æ‹©æ—¶é—´åˆ—ï¼ˆå¹´ä»½ï¼‰Select Time Column",
                df.columns.tolist(),
                key=f"trend_time_col_{i}"
            )

            trend_group_col = st.selectbox(
                "é€‰æ‹©åˆ†ç»„å¯¹è±¡åˆ—ï¼ˆç–¾ç—…/åœ°åŒº/æ€§åˆ«/é£é™©å› ç´ ç­‰ï¼‰Select Grouping Column",
                df.columns.tolist(),
                key=f"trend_group_col_{i}"
            )

            trend_value_col = st.selectbox(
                "é€‰æ‹©è´Ÿæ‹…æ•°å€¼åˆ—ï¼ˆDALYs/æ­»äº¡ç‡/æ‚£ç—…ç‡ç­‰ï¼‰Select Value Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"trend_value_col_{i}"
            )

            selected_groups = st.multiselect(
                "é€‰æ‹©è¦åˆ†æçš„å¯¹è±¡ï¼ˆå¯å¤šé€‰ï¼‰Select Entities to Analyze",
                df[trend_group_col].dropna().unique().tolist(),
                key=f"trend_selected_groups_{i}"
            )

            if selected_groups:
                if st.button(f"æ‰§è¡Œè´Ÿæ‹…è¶‹åŠ¿åˆ†æ Run Burden Trend Analysis Dataset{i + 1}", key=f"trend_run_{i}"):
                    try:
                        df_trend = df[[trend_time_col, trend_group_col, trend_value_col]].dropna()
                        df_trend[trend_time_col] = pd.to_numeric(df_trend[trend_time_col], errors="coerce")
                        df_trend = df_trend.dropna()

                        import plotly.express as px

                        fig = px.line(
                            df_trend[df_trend[trend_group_col].isin(selected_groups)],
                            x=trend_time_col,
                            y=trend_value_col,
                            color=trend_group_col,
                            markers=True,
                            title="ğŸ“ˆ è´Ÿæ‹…éšæ—¶é—´å˜åŒ–è¶‹åŠ¿ Burden Trend Over Time",
                            labels={
                                trend_time_col: "å¹´ä»½ Year",
                                trend_value_col: "è´Ÿæ‹…æ•°å€¼ Burden Value",
                                trend_group_col: "åˆ†ç»„å¯¹è±¡ Group"
                            }
                        )
                        fig.write_image("gbd_trend_plot.png", scale=2)
                        fig.update_traces(mode="lines+markers")
                        st.plotly_chart(fig, use_container_width=True)

                    except Exception as e:
                        st.error(f"âŒ è¶‹åŠ¿åˆ†æå¤±è´¥ Trend Analysis Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†æå¯¹è±¡")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦æ—¶é—´åˆ—ã€åˆ†ç»„åˆ—ã€æ•°å€¼åˆ—")

# ========== ğŸ“‰ GBDå˜åŒ–ç‡åˆ†æä¸“åŒºï¼ˆå˜åŒ–ç‡è®¡ç®—+AAPCï¼‰GBD Change Rate Analysis ========== #
        st.subheader("ğŸ“‰ GBDå˜åŒ–ç‡åˆ†æä¸“åŒº Change Rate Analysis")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.columns) >= 3:
            cr_entity_col = st.selectbox(
                "é€‰æ‹©åˆ†æå¯¹è±¡åˆ—ï¼ˆå›½å®¶/åœ°åŒº/ç–¾ç—…ç­‰ï¼‰Select Entity Column",
                df.columns.tolist(),
                key=f"cr_entity_col_{i}"
            )

            cr_year_col = st.selectbox(
                "é€‰æ‹©æ—¶é—´åˆ—ï¼ˆå¹´ä»½ï¼‰Select Year Column",
                df.columns.tolist(),
                key=f"cr_year_col_{i}"
            )

            cr_value_col = st.selectbox(
                "é€‰æ‹©è´Ÿæ‹…æ•°å€¼åˆ—ï¼ˆDALYs/æ­»äº¡ç‡/æ‚£ç—…ç‡ç­‰ï¼‰Select Value Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"cr_value_col_{i}"
            )

            selected_entities_cr = st.multiselect(
                "é€‰æ‹©è¦åˆ†æçš„å¯¹è±¡ï¼ˆå¯å¤šé€‰ï¼‰Select Entities to Analyze",
                df[cr_entity_col].dropna().unique().tolist(),
                key=f"cr_selected_entities_{i}"
            )

            cr_analysis_type = st.radio(
                "é€‰æ‹©å˜åŒ–ç‡åˆ†æç±»å‹ Select Change Rate Type",
                ["ç®€å•å˜åŒ–ç‡ï¼ˆé¦–å°¾å¹´ï¼‰Simple Change Rate", "å¹´å‡å˜åŒ–ç‡ï¼ˆAAPCï¼‰Average Annual Percentage Change"],
                key=f"cr_analysis_type_{i}"
            )

            if selected_entities_cr:
                if st.button(f"æ‰§è¡Œå˜åŒ–ç‡åˆ†æ Run Change Rate Analysis Dataset{i + 1}", key=f"cr_run_{i}"):
                    try:
                        df_cr = df[[cr_entity_col, cr_year_col, cr_value_col]].dropna()
                        df_cr[cr_year_col] = pd.to_numeric(df_cr[cr_year_col], errors="coerce")
                        df_cr = df_cr.dropna()

                        results = []

                        for entity in selected_entities_cr:
                            sub = df_cr[df_cr[cr_entity_col] == entity]
                            sub = sub.sort_values(by=cr_year_col)

                            if len(sub) >= 2:
                                start_val = sub.iloc[0][cr_value_col]
                                end_val = sub.iloc[-1][cr_value_col]
                                n_years = sub.iloc[-1][cr_year_col] - sub.iloc[0][cr_year_col]

                                if cr_analysis_type == "ç®€å•å˜åŒ–ç‡ï¼ˆé¦–å°¾å¹´ï¼‰Simple Change Rate":
                                    change_rate = ((end_val - start_val) / start_val) * 100
                                else:
                                    if start_val > 0 and n_years > 0:
                                        change_rate = ((end_val / start_val) ** (1 / n_years) - 1) * 100
                                    else:
                                        change_rate = None

                                if change_rate is not None:
                                    results.append((entity, change_rate))

                        df_result = pd.DataFrame(results, columns=["åˆ†æå¯¹è±¡ Entity", "å˜åŒ–ç‡ Change Rate (%)"])

                        st.success(f"âœ… {cr_analysis_type}è®¡ç®—å®Œæˆ Analysis Completed")
                        st.dataframe(df_result)

                        # å¯è§†åŒ–
                        import plotly.express as px

                        fig = px.bar(
                            df_result.sort_values(by="å˜åŒ–ç‡ Change Rate (%)"),
                            x="å˜åŒ–ç‡ Change Rate (%)", y="åˆ†æå¯¹è±¡ Entity",
                            orientation="h",
                            title=f"ğŸ“‰ {cr_analysis_type}ç»“æœ",
                            text_auto=".2f"
                        )
                        fig.write_image("gbd_change_rate_plot.png", scale=2)
                        fig.update_layout(yaxis={'categoryorder': 'total ascending'})
                        st.plotly_chart(fig, use_container_width=True)

                    except Exception as e:
                        st.error(f"âŒ å˜åŒ–ç‡åˆ†æå¤±è´¥ Change Rate Analysis Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªåˆ†æå¯¹è±¡")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦å¯¹è±¡åˆ—ã€æ—¶é—´åˆ—ã€æ•°å€¼åˆ—")

# ========== ğŸ§¬ GBDé£é™©å› ç´ å½’å› åˆ†æä¸“åŒºï¼ˆé£é™©Topåˆ†æ+PAFå½’å› åˆ†æï¼‰GBD Risk Factors Attribution ========== #
        st.subheader("ğŸ§¬ GBDé£é™©å› ç´ å½’å› åˆ†æ Risk Factors Attribution Analysis")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.columns) >= 3:
            risk_factor_col = st.selectbox(
                "é€‰æ‹©é£é™©å› ç´ åˆ— Select Risk Factor Column",
                df.columns.tolist(),
                key=f"risk_factor_col_{i}"
            )

            burden_value_col = st.selectbox(
                "é€‰æ‹©è´Ÿæ‹…æ•°å€¼åˆ—ï¼ˆå¦‚å½’å› DALYsæˆ–æ­»äº¡æ•°ï¼‰Select Burden Value Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"risk_burden_value_col_{i}"
            )

            # PAFç›¸å…³åˆ—
            paf_exposure_col = st.selectbox(
                "é€‰æ‹©æš´éœ²ç‡åˆ—ï¼ˆExposure Rate 0-1ä¹‹é—´ï¼‰Select Exposure Rate Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"risk_exposure_col_{i}"
            )

            paf_rr_col = st.selectbox(
                "é€‰æ‹©ç›¸å¯¹é£é™©åˆ—ï¼ˆRelative Riskï¼‰Select Relative Risk Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"risk_rr_col_{i}"
            )

            selected_risks = st.multiselect(
                "é€‰æ‹©è¦åˆ†æçš„é£é™©å› ç´ ï¼ˆå¯å¤šé€‰ï¼‰Select Risks to Analyze",
                df[risk_factor_col].dropna().unique().tolist(),
                key=f"risk_selected_factors_{i}"
            )

            if selected_risks:
                if st.button(f"æ‰§è¡Œé£é™©å› ç´ å½’å› åˆ†æ Run Risk Attribution Analysis Dataset{i + 1}", key=f"risk_run_{i}"):
                    try:
                        df_risk = df[[risk_factor_col, burden_value_col, paf_exposure_col, paf_rr_col]].dropna()

                        # Top10é£é™©è´¡çŒ®åˆ†æ
                        df_top = df_risk[df_risk[risk_factor_col].isin(selected_risks)]
                        df_top = df_top.groupby(risk_factor_col)[burden_value_col].sum().reset_index()
                        df_top = df_top.sort_values(by=burden_value_col, ascending=False).head(10)

                        # å½’å› é£é™©æ¯”ä¾‹PAFè®¡ç®—
                        paf_results = []
                        for _, row in df_risk.iterrows():
                            exposure = row[paf_exposure_col]
                            rr = row[paf_rr_col]
                            if 0 <= exposure <= 1 and rr >= 1:
                                paf = (exposure * (rr - 1)) / (exposure * (rr - 1) + 1)
                                paf_results.append((row[risk_factor_col], paf * 100))

                        df_paf = pd.DataFrame(paf_results, columns=["é£é™©å› ç´  Risk Factor", "PAF (%)"])
                        df_paf = df_paf[df_paf["é£é™©å› ç´  Risk Factor"].isin(selected_risks)]

                        st.success("âœ… é£é™©Topåˆ†æå’ŒPAFå½’å› æ¯”ä¾‹è®¡ç®—å®Œæˆ Analysis Completed")

                        st.markdown("### ğŸ“Š é£é™©å› ç´ è´Ÿæ‹…Top10åˆ†æ Risk Factors Burden Top10")
                        st.dataframe(df_top)

                        import plotly.express as px

                        fig1 = px.bar(
                            df_top.sort_values(by=burden_value_col),
                            x=burden_value_col, y=risk_factor_col,
                            orientation="h",
                            title="ğŸ§¬ é£é™©å› ç´ è´Ÿæ‹…Top10 Risk Burden Top10",
                            text_auto=".2s"
                        )
                        fig1.write_image("risk_top10_plot.png", scale=2)
                        fig1.update_layout(yaxis={'categoryorder': 'total ascending'})
                        st.plotly_chart(fig1, use_container_width=True)

                        st.markdown("### ğŸ“ˆ å½’å› é£é™©æ¯”ä¾‹PAFåˆ†æ Population Attributable Fraction (PAF)")
                        st.dataframe(df_paf)

                        fig2 = px.bar(
                            df_paf.sort_values(by="PAF (%)"),
                            x="PAF (%)", y="é£é™©å› ç´  Risk Factor",
                            orientation="h",
                            title="ğŸ§¬ é£é™©å› ç´ PAFå½’å› æ¯”ä¾‹ Risk Factors PAF",
                            text_auto=".2f"
                        )
                        fig2.write_image("risk_paf_plot.png", scale=2)
                        fig2.update_layout(yaxis={'categoryorder': 'total ascending'})
                        st.plotly_chart(fig2, use_container_width=True)

                    except Exception as e:
                        st.error(f"âŒ é£é™©å½’å› åˆ†æå¤±è´¥ Risk Attribution Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªé£é™©å› ç´ ")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦é£é™©åˆ—ã€è´Ÿæ‹…åˆ—ã€æš´éœ²ç‡åˆ—ã€ç›¸å¯¹é£é™©åˆ—")

# ========== ğŸŒŸ GBDç”Ÿå­˜åˆ†æä¸“åŒºï¼ˆKaplan-Meier + Stratified KM + Coxå›å½’ï¼‰Survival Analysis ========== #
        st.subheader("ğŸŒŸ GBDç”Ÿå­˜åˆ†æä¸“åŒº Survival Analysis")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.columns) >= 3:
            surv_time_col = st.selectbox(
                "é€‰æ‹©ç”Ÿå­˜æ—¶é—´åˆ—ï¼ˆTime-to-Event Columnï¼‰",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"surv_time_col_{i}"
            )

            surv_event_col = st.selectbox(
                "é€‰æ‹©äº‹ä»¶çŠ¶æ€åˆ—ï¼ˆ0=æ— äº‹ä»¶ï¼Œ1=äº‹ä»¶ï¼‰Select Event Status Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"surv_event_col_{i}"
            )

            analysis_type = st.radio(
                "é€‰æ‹©ç”Ÿå­˜åˆ†æç±»å‹ Select Survival Analysis Type",
                ["å•å› ç´ Kaplan-Meierç”Ÿå­˜æ›²çº¿", "åˆ†å±‚Kaplan-Meierç”Ÿå­˜æ›²çº¿", "Coxæ¯”ä¾‹é£é™©å›å½’"],
                key=f"surv_analysis_type_{i}"
            )

            if analysis_type in ["å•å› ç´ Kaplan-Meierç”Ÿå­˜æ›²çº¿", "åˆ†å±‚Kaplan-Meierç”Ÿå­˜æ›²çº¿"]:
                strat_cols = st.multiselect(
                    "é€‰æ‹©åˆ†ç»„/åˆ†å±‚å˜é‡ï¼ˆå¯é€‰ï¼‰Select Group/Stratification Variables",
                    df.select_dtypes(exclude=np.number).columns.tolist(),
                    key=f"surv_strat_cols_{i}"
                )

            else:
                cox_features = st.multiselect(
                    "é€‰æ‹©Coxå›å½’ç‰¹å¾å˜é‡ï¼ˆå¯æ•°å€¼/å¯åˆ†ç±»ï¼‰Select Features for Cox Regression",
                    df.columns.tolist(),
                    key=f"cox_features_{i}"
                )

            if st.button(f"æ‰§è¡Œç”Ÿå­˜åˆ†æ Run Survival Analysis Dataset{i + 1}", key=f"surv_run_{i}"):
                try:
                    from lifelines import KaplanMeierFitter, CoxPHFitter
                    from lifelines.statistics import multivariate_logrank_test
                    import matplotlib.pyplot as plt

                    df_surv = df.dropna(subset=[surv_time_col, surv_event_col])

                    if analysis_type in ["å•å› ç´ Kaplan-Meierç”Ÿå­˜æ›²çº¿", "åˆ†å±‚Kaplan-Meierç”Ÿå­˜æ›²çº¿"]:
                        if strat_cols:
                            df_surv["Group"] = df_surv[strat_cols].apply(lambda row: "-".join(row.values.astype(str)),
                                                                         axis=1)
                        else:
                            df_surv["Group"] = "All"

                        groups = df_surv["Group"].unique()

                        fig, ax = plt.subplots(figsize=(8, 6))
                        for group in groups:
                            ix = df_surv["Group"] == group
                            kmf = KaplanMeierFitter()
                            kmf.fit(df_surv.loc[ix, surv_time_col], event_observed=df_surv.loc[ix, surv_event_col],
                                    label=group)
                            kmf.plot_survival_function(ax=ax)

                        plt.title("ğŸŒŸ Kaplan-Meierç”Ÿå­˜æ›²çº¿ Kaplan-Meier Survival Curves")
                        plt.xlabel("ç”Ÿå­˜æ—¶é—´ Survival Time")
                        plt.ylabel("ç”Ÿå­˜æ¦‚ç‡ Survival Probability")
                        plt.grid(True)
                        st.pyplot(fig)
                        fig.savefig("km_survival_curve.png", dpi=300)

                        if len(groups) > 1:
                            results = multivariate_logrank_test(
                                df_surv[surv_time_col],
                                groups=df_surv["Group"],
                                event_observed=df_surv[surv_event_col]
                            )
                            p_value = results.p_value
                            st.success(f"âœ… å¤šç»„Log-rankæ£€éªŒå®Œæˆ P-value: {p_value:.4f}")

                    else:
                        if not cox_features:
                            st.warning("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªCoxå›å½’ç‰¹å¾å˜é‡")
                        else:
                            df_cox = df_surv[[surv_time_col, surv_event_col] + cox_features].dropna()
                            df_cox_encoded = pd.get_dummies(df_cox, columns=[col for col in cox_features if
                                                                             df[col].dtype == 'object' or df[
                                                                                 col].dtype.name == 'category'])

                            cph = CoxPHFitter()
                            cph.fit(df_cox_encoded, duration_col=surv_time_col, event_col=surv_event_col)

                            st.success("âœ… Coxå›å½’æ¨¡å‹æ‹Ÿåˆå®Œæˆ Cox Model Fitted")
                            st.dataframe(cph.summary)

                            import plotly.express as px

                            coef_df = cph.summary.reset_index()
                            fig = px.bar(
                                coef_df,
                                x="exp(coef)", y="index",
                                orientation="h",
                                title="ğŸ§¬ Coxå›å½’æ¨¡å‹ç‰¹å¾é£é™©æ¯” Hazard Ratios",
                                labels={"index": "å˜é‡ Variable", "exp(coef)": "é£é™©æ¯” Hazard Ratio"},
                                text_auto=".2f"
                            )
                            fig.write_image("cox_hr_plot.png", scale=2)
                            fig.update_layout(yaxis={'categoryorder': 'total ascending'})
                            st.plotly_chart(fig, use_container_width=True)

                except Exception as e:
                    st.error(f"âŒ ç”Ÿå­˜åˆ†æå¤±è´¥ Survival Analysis Failed: {e}")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦ç”Ÿå­˜æ—¶é—´åˆ—ã€äº‹ä»¶åˆ—")

# ========== ğŸ”ï¸ GBDè´Ÿæ‹…å †ç§¯è¶‹åŠ¿åˆ†æï¼ˆArea Plotï¼‰GBD Burden Stacked Area Analysis ========== #
        st.subheader("ğŸ”ï¸ GBDè´Ÿæ‹…å †ç§¯è¶‹åŠ¿åˆ†æ Stacked Area Trend Analysis")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.columns) >= 3:
            area_time_col = st.selectbox(
                "é€‰æ‹©æ—¶é—´åˆ—ï¼ˆå¹´ä»½ï¼‰Select Time Column",
                df.columns.tolist(),
                key=f"area_time_col_{i}"
            )

            area_group_col = st.selectbox(
                "é€‰æ‹©åˆ†ç»„åˆ—ï¼ˆç–¾ç—…/é£é™©å› ç´ ç­‰ï¼‰Select Grouping Column",
                df.columns.tolist(),
                key=f"area_group_col_{i}"
            )

            area_value_col = st.selectbox(
                "é€‰æ‹©æ•°å€¼åˆ—ï¼ˆDALYs/æ­»äº¡ç‡/æ‚£ç—…ç‡ç­‰ï¼‰Select Value Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"area_value_col_{i}"
            )

            selected_groups_area = st.multiselect(
                "é€‰æ‹©è¦åˆ†æçš„å¯¹è±¡ï¼ˆå¯å¤šé€‰ï¼‰Select Entities to Include",
                df[area_group_col].dropna().unique().tolist(),
                key=f"area_selected_groups_{i}"
            )

            if selected_groups_area:
                if st.button(f"æ‰§è¡Œè´Ÿæ‹…å †ç§¯è¶‹åŠ¿åˆ†æ Run Stacked Area Trend Analysis Dataset{i + 1}",
                             key=f"area_run_{i}"):
                    try:
                        df_area = df[[area_time_col, area_group_col, area_value_col]].dropna()
                        df_area[area_time_col] = pd.to_numeric(df_area[area_time_col], errors="coerce")
                        df_area = df_area.dropna()

                        df_area = df_area[df_area[area_group_col].isin(selected_groups_area)]

                        import plotly.express as px

                        fig = px.area(
                            df_area,
                            x=area_time_col,
                            y=area_value_col,
                            color=area_group_col,
                            title="ğŸ”ï¸ è´Ÿæ‹…å †ç§¯è¶‹åŠ¿åˆ†æ Stacked Area Burden Trends",
                            labels={
                                area_time_col: "å¹´ä»½ Year",
                                area_value_col: "è´Ÿæ‹…æ•°å€¼ Burden Value",
                                area_group_col: "åˆ†ç»„å¯¹è±¡ Group"
                            }
                        )
                        st.plotly_chart(fig, use_container_width=True)

                    except Exception as e:
                        st.error(f"âŒ å †ç§¯è¶‹åŠ¿åˆ†æå¤±è´¥ Area Plot Analysis Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå¯¹è±¡è¿›è¡Œå †ç§¯åˆ†æ")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦æ—¶é—´åˆ—ã€åˆ†ç»„åˆ—ã€æ•°å€¼åˆ—")

# ========== ğŸ† GBDå›½å®¶è´Ÿæ‹…æ’åå˜åŒ–åˆ†æï¼ˆéšæ—¶é—´å˜åŒ–ï¼‰GBD Country Burden Ranking Trend ========== #
        st.subheader("ğŸ† GBDå›½å®¶è´Ÿæ‹…æ’åå˜åŒ–åˆ†æ Country Burden Ranking Trend")
        if not dfs:
            st.warning("âš  å½“å‰æ²¡æœ‰ä¸Šä¼ æ•°æ®ï¼Œè¯·å…ˆåœ¨ä¾§è¾¹æ ä¸Šä¼ æ•°æ®ï¼")
            st.stop()

        if len(df.columns) >= 3:
            rank_time_col = st.selectbox(
                "é€‰æ‹©æ—¶é—´åˆ—ï¼ˆå¹´ä»½ï¼‰Select Time Column",
                df.columns.tolist(),
                key=f"rank_time_col_{i}"
            )

            rank_country_col = st.selectbox(
                "é€‰æ‹©å›½å®¶åˆ— Select Country Column",
                df.columns.tolist(),
                key=f"rank_country_col_{i}"
            )

            rank_value_col = st.selectbox(
                "é€‰æ‹©è´Ÿæ‹…æ•°å€¼åˆ—ï¼ˆDALYs/æ­»äº¡ç‡/æ‚£ç—…ç‡ç­‰ï¼‰Select Burden Value Column",
                df.select_dtypes(include=np.number).columns.tolist(),
                key=f"rank_value_col_{i}"
            )

            selected_countries_rank = st.multiselect(
                "é€‰æ‹©è¦è¿½è¸ªæ’åå˜åŒ–çš„å›½å®¶ï¼ˆå¯å¤šé€‰ï¼‰Select Countries to Track",
                df[rank_country_col].dropna().unique().tolist(),
                key=f"rank_selected_countries_{i}"
            )

            if selected_countries_rank:
                if st.button(f"æ‰§è¡Œå›½å®¶è´Ÿæ‹…æ’åå˜åŒ–åˆ†æ Run Country Ranking Trend Analysis Dataset{i + 1}",
                             key=f"rank_run_{i}"):
                    try:
                        df_rank = df[[rank_time_col, rank_country_col, rank_value_col]].dropna()
                        df_rank[rank_time_col] = pd.to_numeric(df_rank[rank_time_col], errors="coerce")
                        df_rank = df_rank.dropna()

                        # æ¯ä¸€å¹´å†…éƒ¨æ’å
                        df_rank["è´Ÿæ‹…æ’å Rank"] = df_rank.groupby(rank_time_col)[rank_value_col].rank(method="min",
                                                                                                       ascending=False)

                        df_plot = df_rank[df_rank[rank_country_col].isin(selected_countries_rank)]

                        import plotly.express as px

                        fig = px.line(
                            df_plot,
                            x=rank_time_col,
                            y="è´Ÿæ‹…æ’å Rank",
                            color=rank_country_col,
                            markers=True,
                            title="ğŸ† å›½å®¶è´Ÿæ‹…æ’åéšæ—¶é—´å˜åŒ– Country Burden Ranking Trend",
                            labels={
                                rank_time_col: "å¹´ä»½ Year",
                                "è´Ÿæ‹…æ’å Rank": "æ’å Rank",
                                rank_country_col: "å›½å®¶ Country"
                            }
                        )
                        fig.update_yaxes(autorange="reversed")  # åæ¬¡1åœ¨ä¸Š
                        st.plotly_chart(fig, use_container_width=True)

                    except Exception as e:
                        st.error(f"âŒ å›½å®¶æ’åå˜åŒ–åˆ†æå¤±è´¥ Country Ranking Analysis Failed: {e}")
            else:
                st.info("âš  è¯·è‡³å°‘é€‰æ‹©ä¸€ä¸ªå›½å®¶è¿›è¡Œæ’ååˆ†æ")
        else:
            st.info("âš  å½“å‰æ•°æ®å­—æ®µä¸è¶³ï¼Œè‡³å°‘éœ€è¦æ—¶é—´åˆ—ã€å›½å®¶åˆ—ã€æ•°å€¼åˆ—")

# ========== ğŸ“‘ å®Œæ•´ç‰ˆä¸“ä¸šæŠ¥å‘Šç”Ÿæˆå™¨ Generate Full Analysis Report ========== #
import docx
from docx.shared import Inches
import os
import pandas as pd

st.sidebar.header("ğŸ“‘ ç”Ÿæˆä¸“ä¸šåˆ†ææŠ¥å‘Š Generate Report")
generate_report = st.sidebar.checkbox("å¯ç”¨åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ Enable Report Generator")

if generate_report and dfs:
    st.header("ğŸ“‘ åˆ†ææŠ¥å‘Šç”Ÿæˆå™¨ Report Generator")

    report_modules = st.multiselect(
        "è¯·é€‰æ‹©éœ€è¦çº³å…¥æŠ¥å‘Šçš„åŠŸèƒ½æ¨¡å—ï¼ˆå¯å¤šé€‰ï¼‰Select Modules to Include in Report",
        [
            "æè¿°æ€§ç»Ÿè®¡åˆ†æ",
            "ç›¸å…³æ€§åˆ†æ",
            "åˆ†ç»„å¯¹æ¯”åˆ†æ",
            "ç”Ÿå­˜åˆ†æ",
            "æ—¶é—´åºåˆ—é¢„æµ‹åˆ†æ",
            "PCAåˆ†æ",
            "èšç±»åˆ†æ",
            "æœºå™¨å­¦ä¹ å»ºæ¨¡",
            "GBDåœ°ç†åˆ†å¸ƒåˆ†æ",
            "GBDè¶‹åŠ¿åˆ†æ",
            "GBDå˜åŒ–ç‡åˆ†æ",
            "GBDé£é™©å› ç´ å½’å› åˆ†æ",
            "GBDç”Ÿå­˜åˆ†æ"
        ],
        default=["æè¿°æ€§ç»Ÿè®¡åˆ†æ", "ç›¸å…³æ€§åˆ†æ", "GBDè¶‹åŠ¿åˆ†æ"]
    )

    report_name = st.text_input("è¾“å…¥æŠ¥å‘Šæ–‡ä»¶åï¼ˆæ— éœ€åŠ åç¼€ï¼‰Enter Report Filename", "åŒ»å­¦æ•°æ®åˆ†ææŠ¥å‘Š")

    if st.button("ğŸ“¥ ç”Ÿæˆå¹¶ä¸‹è½½WordæŠ¥å‘Š Generate & Download Report"):
        try:
            doc = docx.Document()

            # ===== æŠ¥å‘Šå°é¢ =====
            doc.add_heading("åŒ»å­¦æ•°æ®ç»Ÿè®¡åˆ†æä¸å¯è§†åŒ–æŠ¥å‘Š", 0)
            doc.add_paragraph(f"æŠ¥å‘Šåç§°ï¼š{report_name}")
            doc.add_paragraph(f"å•ä½ï¼šXXå•ä½ï¼ˆå¯å¡«å†™ä½ çš„å­¦æ ¡ã€åŒ»é™¢æˆ–å®éªŒå®¤ï¼‰")
            doc.add_paragraph(f"ç”Ÿæˆæ—¶é—´ï¼š{pd.Timestamp.now():%Y-%m-%d %H:%M}")
            doc.add_page_break()

            doc.add_page_break()

            # ===== éå†ç”¨æˆ·é€‰æ‹©çš„æ¨¡å—ï¼Œç”Ÿæˆå¯¹åº”å†…å®¹ =====
            # åœ¨ for module in report_modules: å¾ªç¯å‰æ·»åŠ è¿™ä¸€è¡Œ
            chapter_number = 1

            # ä¸‹é¢æ˜¯for module in report_modules:å¾ªç¯å†…å®¹
            for module in report_modules:
                doc.add_heading(f"ç¬¬{chapter_number}ç«  {module}", level=1)
                chapter_number += 1

                if module == "æè¿°æ€§ç»Ÿè®¡åˆ†æ":
                    doc.add_paragraph(
                        "ã€æè¿°æ€§ç»Ÿè®¡åˆ†æ Descriptive Statisticsã€‘\n\n"
                        "æœ¬æ¨¡å—å¯¹æ‰€é€‰æ•°å€¼å‹å˜é‡è¿›è¡ŒåŸºæœ¬ç»Ÿè®¡æè¿°ã€‚\n"
                        "- å‡å€¼ã€ä¸­ä½æ•°ã€æ ‡å‡†å·®ã€ååº¦ã€å³°åº¦å·²ç»Ÿè®¡ã€‚\n"
                        "- å¤§éƒ¨åˆ†å˜é‡åˆ†å¸ƒæ¥è¿‘æ­£æ€ï¼Œæ•°æ®è´¨é‡è‰¯å¥½ã€‚\n\n"
                        "ç»“æœä¸ºåç»­åˆ†æå’Œå»ºæ¨¡æä¾›äº†åŸºç¡€ã€‚"
                    )
                    if os.path.exists("desc_stats_table.png"):
                        doc.add_picture("desc_stats_table.png", width=Inches(5))
                        doc.add_paragraph("â–² æè¿°æ€§ç»Ÿè®¡ç›´æ–¹å›¾")

                if module == "ç›¸å…³æ€§åˆ†æ":
                    doc.add_paragraph(
                        "ã€ç›¸å…³æ€§åˆ†æ Correlation Analysisã€‘\n\n"
                        "åˆ†æäº†æ•°å€¼å˜é‡ä¹‹é—´çš„Pearson/Spearmanç›¸å…³æ€§ã€‚\n"
                        "- ç›¸å…³ç³»æ•°åŒºé—´ä¸º [-1, 1]ã€‚\n"
                        "- å­˜åœ¨è‹¥å¹²é«˜ç›¸å…³å˜é‡å¯¹ã€‚\n\n"
                        "ç»“æœä¸ºåç»­å»ºæ¨¡æä¾›äº†å˜é‡ç­›é€‰å‚è€ƒã€‚"
                    )
                    if os.path.exists("correlation_heatmap.png"):
                        doc.add_picture("correlation_heatmap.png", width=Inches(5))
                        doc.add_paragraph("â–² ç›¸å…³æ€§çŸ©é˜µçƒ­åŠ›å›¾")

                if module == "åˆ†ç»„å¯¹æ¯”åˆ†æ":
                    doc.add_paragraph(
                        "ã€åˆ†ç»„å¯¹æ¯”åˆ†æ Group Comparison Analysisã€‘\n\n"
                        "æ¯”è¾ƒäº†ä¸åŒç»„åˆ«ä¹‹é—´çš„å…³é”®å˜é‡å·®å¼‚ã€‚\n"
                        "- ä¸¤ç»„ä½¿ç”¨tæ£€éªŒæˆ–Mann-Whitneyæ£€éªŒã€‚\n"
                        "- å¤šç»„ä½¿ç”¨ANOVAæˆ–Kruskal-Wallisæ£€éªŒã€‚\n\n"
                        "æ˜¾è‘—æ€§å·®å¼‚å˜é‡æœ‰åŠ©äºè¯†åˆ«å½±å“å› ç´ ã€‚"
                    )
                    if os.path.exists("group_comparison_plot.png"):
                        doc.add_picture("group_comparison_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² åˆ†ç»„å¯¹æ¯”ç®±çº¿å›¾/å°æç´å›¾")

                if module == "ç”Ÿå­˜åˆ†æ":
                    doc.add_paragraph(
                        "ã€ç”Ÿå­˜åˆ†æ Survival Analysisã€‘\n\n"
                        "é‡‡ç”¨Kaplan-Meieræ›²çº¿ä¸Coxå›å½’æ¨¡å‹è¿›è¡Œç”Ÿå­˜åˆ†æã€‚\n"
                        "- ä¸åŒç»„åˆ«ä¸­ä½ç”Ÿå­˜æ—¶é—´åŠå·®å¼‚æ€§åˆ†æã€‚\n"
                        "- è¯†åˆ«ç‹¬ç«‹å±é™©å› ç´ åŠä¿æŠ¤å› ç´ ã€‚\n\n"
                        "ç»“æœç”¨äºé£é™©åˆ†å±‚å’Œé¢„åè¯„ä¼°ã€‚"
                    )
                    if os.path.exists("km_survival_curve.png"):
                        doc.add_picture("km_survival_curve.png", width=Inches(5))
                        doc.add_paragraph("â–² Kaplan-Meierç”Ÿå­˜æ›²çº¿")
                    if os.path.exists("cox_hr_plot.png"):
                        doc.add_picture("cox_hr_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² Coxå›å½’é£é™©æ¯”æ¡å½¢å›¾")

                if module == "æ—¶é—´åºåˆ—é¢„æµ‹åˆ†æ":
                    doc.add_paragraph(
                        "ã€æ—¶é—´åºåˆ—é¢„æµ‹åˆ†æ Time Series Forecasting Analysisã€‘\n\n"
                        "ä½¿ç”¨Auto-ARIMAå»ºæ¨¡ï¼Œé¢„æµ‹æœªæ¥è¶‹åŠ¿ã€‚\n"
                        "- é¢„æµ‹åŒºé—´ä¸è¶‹åŠ¿æ–¹å‘å·²ç»˜åˆ¶ã€‚\n\n"
                        "ç»“æœç”¨äºç–¾ç—…è´Ÿæ‹…å˜åŒ–è¶‹åŠ¿é¢„æµ‹ã€‚"
                    )
                    if os.path.exists("time_series_forecast.png"):
                        doc.add_picture("time_series_forecast.png", width=Inches(5))
                        doc.add_paragraph("â–² æ—¶é—´åºåˆ—è¶‹åŠ¿é¢„æµ‹å›¾")

                if module == "PCAåˆ†æ":
                    doc.add_paragraph(
                        "ã€ä¸»æˆåˆ†åˆ†æ PCAã€‘\n\n"
                        "å¯¹é«˜ç»´æ•°æ®è¿›è¡Œé™ç»´å¤„ç†ï¼Œæå–ä¸»è¦æˆåˆ†ã€‚\n"
                        "- å‰ä¸¤ä¸»æˆåˆ†è§£é‡Šä¸»è¦å˜å¼‚ã€‚\n"
                        "- å¯è§†åŒ–æ ·æœ¬åˆ†å¸ƒç»“æ„ã€‚\n\n"
                        "PCAåˆ†ææ­ç¤ºäº†æ•°æ®å†…éƒ¨æ½œåœ¨ç»“æ„ã€‚"
                    )
                    if os.path.exists("pca_plot.png"):
                        doc.add_picture("pca_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² PCAä¸»æˆåˆ†æ•£ç‚¹å›¾")

                if module == "èšç±»åˆ†æ":
                    doc.add_paragraph(
                        "ã€èšç±»åˆ†æ Clustering Analysisã€‘\n\n"
                        "é€šè¿‡æ— ç›‘ç£å­¦ä¹ æ–¹æ³•æ¢ç´¢æ•°æ®æ½œåœ¨åˆ†ç»„ã€‚\n"
                        "- æ ·æœ¬åœ¨2D/3Dç©ºé—´ä¸­èšç±»ç»“æœå¯è§†åŒ–ã€‚\n\n"
                        "èšç±»åˆ†ææ­ç¤ºæ½œåœ¨äºšç¾¤ä½“ã€‚"
                    )
                    if os.path.exists("cluster_plot.png"):
                        doc.add_picture("cluster_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² èšç±»æ•£ç‚¹å›¾")

                if module == "æœºå™¨å­¦ä¹ å»ºæ¨¡":
                    doc.add_paragraph(
                        "ã€æœºå™¨å­¦ä¹ å»ºæ¨¡ Machine Learning Modelingã€‘\n\n"
                        "é‡‡ç”¨Logisticå›å½’å’ŒXGBoostå»ºæ¨¡ã€‚\n"
                        "- æ¨¡å‹AUCã€çµæ•åº¦ã€ç‰¹å¼‚æ€§è¯„ä¼°ã€‚\n"
                        "- ç‰¹å¾é‡è¦æ€§æ’åºå¯è§†åŒ–ã€‚\n\n"
                        "å»ºæ¨¡ç»“æœç”¨äºé¢„æµ‹å’Œå˜é‡ç­›é€‰ã€‚"
                    )
                    if os.path.exists("logistic_roc_curve.png"):
                        doc.add_picture("logistic_roc_curve.png", width=Inches(5))
                        doc.add_paragraph("â–² Logisticå›å½’ROCæ›²çº¿")
                    if os.path.exists("xgboost_feature_importance.png"):
                        doc.add_picture("xgboost_feature_importance.png", width=Inches(5))
                        doc.add_paragraph("â–² XGBoostç‰¹å¾é‡è¦æ€§å›¾")

                if module == "GBDåœ°ç†åˆ†å¸ƒåˆ†æ":
                    doc.add_paragraph(
                        "ã€GBDåœ°ç†åˆ†å¸ƒåˆ†æ Geographic Distribution Analysisã€‘\n\n"
                        "å±•ç¤ºäº†å…¨çƒç–¾ç—…è´Ÿæ‹…çš„åœ°ç†åˆ†å¸ƒç‰¹å¾ã€‚\n"
                        "- ä¸åŒå›½å®¶å’Œåœ°åŒºè´Ÿæ‹…å·®å¼‚æ˜æ˜¾ã€‚\n\n"
                        "ä¸ºåˆ¶å®šåŒºåŸŸå¹²é¢„ç­–ç•¥æä¾›å‚è€ƒã€‚"
                    )
                    if os.path.exists("gbd_geographic_distribution.png"):
                        doc.add_picture("gbd_geographic_distribution.png", width=Inches(5))
                        doc.add_paragraph("â–² ç–¾ç—…è´Ÿæ‹…åœ°ç†åˆ†å¸ƒå›¾")

                if module == "GBDè¶‹åŠ¿åˆ†æ":
                    doc.add_paragraph(
                        "ã€GBDè´Ÿæ‹…æ—¶é—´è¶‹åŠ¿åˆ†æ Burden Trend Over Time Analysisã€‘\n\n"
                        "åˆ†æäº†ç–¾ç—…è´Ÿæ‹…éšæ—¶é—´å˜åŒ–çš„è¶‹åŠ¿ã€‚\n"
                        "- ä¸Šå‡ã€ä¸‹é™ã€ç¨³å®šè¶‹åŠ¿æ€»ç»“ã€‚\n\n"
                        "è¶‹åŠ¿åˆ†ææŒ‡å¯¼è´Ÿæ‹…å˜åŒ–ç›‘æµ‹ã€‚"
                    )
                    if os.path.exists("gbd_trend_plot.png"):
                        doc.add_picture("gbd_trend_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² ç–¾ç—…è´Ÿæ‹…æ—¶é—´è¶‹åŠ¿å›¾")

                if module == "GBDå˜åŒ–ç‡åˆ†æ":
                    doc.add_paragraph(
                        "ã€GBDå˜åŒ–ç‡åˆ†æ Burden Change Rate Analysisã€‘\n\n"
                        "è®¡ç®—äº†å¹´å‡å˜åŒ–ç‡ï¼ˆAAPCï¼‰åŠç®€å•å˜åŒ–ç‡ã€‚\n"
                        "- è¯†åˆ«å¢é•¿æœ€å¿«å’Œä¸‹é™æœ€å¿«ç–¾ç—…ã€‚\n\n"
                        "å˜åŒ–ç‡åæ˜ ç–¾ç—…æµè¡Œè¶‹åŠ¿å˜åŒ–ã€‚"
                    )
                    if os.path.exists("gbd_change_rate_plot.png"):
                        doc.add_picture("gbd_change_rate_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² ç–¾ç—…è´Ÿæ‹…å˜åŒ–ç‡æ¡å½¢å›¾")

                if module == "GBDé£é™©å› ç´ å½’å› åˆ†æ":
                    doc.add_paragraph(
                        "ã€GBDé£é™©å› ç´ å½’å› åˆ†æ Risk Factors Attribution Analysisã€‘\n\n"
                        "åˆ†æäº†å„ä¸»è¦é£é™©å› ç´ å¯¹è´Ÿæ‹…çš„è´¡çŒ®ã€‚\n"
                        "- å½’å› é£é™©æ¯”ä¾‹ï¼ˆPAFï¼‰è®¡ç®—å®Œæˆã€‚\n\n"
                        "æç¤ºå¹²é¢„ä¼˜å…ˆçº§ã€‚"
                    )
                    if os.path.exists("risk_top10_plot.png"):
                        doc.add_picture("risk_top10_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² é£é™©å› ç´ è´Ÿæ‹…Top10å›¾")
                    if os.path.exists("risk_paf_plot.png"):
                        doc.add_picture("risk_paf_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² é£é™©å› ç´ PAFå›¾")

                if module == "GBDç”Ÿå­˜åˆ†æ":
                    doc.add_paragraph(
                        "ã€GBDç”Ÿå­˜åˆ†æ GBD Survival Analysisã€‘\n\n"
                        "åŸºäºKaplan-Meierå’ŒCoxæ¨¡å‹åˆ†æå„åœ°åŒºç”Ÿå­˜å·®å¼‚ã€‚\n"
                        "- ä¸­ä½ç”Ÿå­˜æ—¶é—´åŠå±é™©å› ç´ è¯†åˆ«ã€‚\n\n"
                        "ç»“æœç”¨äºç”Ÿå­˜é¢„åç ”ç©¶ã€‚"
                    )
                    if os.path.exists("gbd_km_survival_curve.png"):
                        doc.add_picture("gbd_km_survival_curve.png", width=Inches(5))
                        doc.add_paragraph("â–² GBDåˆ†ç»„Kaplan-Meieræ›²çº¿")
                    if os.path.exists("gbd_cox_hr_plot.png"):
                        doc.add_picture("gbd_cox_hr_plot.png", width=Inches(5))
                        doc.add_paragraph("â–² GBD Coxå›å½’é£é™©æ¯”æ¡å½¢å›¾")

                # æ¯ä¸ªæ¨¡å—æœ€ååŠ ä¸€ä¸ªåˆ†é¡µ
                doc.add_page_break()

            # ===== ä¿å­˜æ–‡æ¡£ =====
            output_path = f"{report_name}.docx"
            doc.save(output_path)

            with open(output_path, "rb") as f:
                st.download_button(
                    label="ğŸ“¥ ä¸‹è½½ç”Ÿæˆçš„WordæŠ¥å‘Š Download Report",
                    data=f,
                    file_name=f"{report_name}.docx",
                    mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document"
                )

            st.success("âœ… æŠ¥å‘Šç”ŸæˆæˆåŠŸï¼Report Generated Successfully!")

        except Exception as e:
            st.error(f"âŒ æŠ¥å‘Šç”Ÿæˆå¤±è´¥ Report Generation Failed: {e}")



